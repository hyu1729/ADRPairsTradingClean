{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from statsmodels import regression,stats\n",
    "import math\n",
    "import datetime \n",
    "import statsmodels.formula.api as smf \n",
    "from datetime import date, time, datetime, timedelta\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(country, adr, fx_dict):\n",
    "    adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "    stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "    fx_path = fx_dict[country][0]\n",
    "    fx_type =  fx_dict[country][1]\n",
    "    try:\n",
    "        adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "    except:\n",
    "        print(f\"no data for ADR data of {adr} from {country}\")\n",
    "        return None\n",
    "    try:\n",
    "        stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "    except:\n",
    "        print(f\"no data for underlying data of {adr} from {country}\")\n",
    "        return None\n",
    "    fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "\n",
    "    merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "    merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n",
    "\n",
    "    if fx_type == 1:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "    else:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']*merged_df['fx_open']\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close']*merged_df['fx_close']\n",
    "\n",
    "    ratio =round(merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open'])\n",
    "    if ratio >= 1:\n",
    "        merged_df['adr_open'] = merged_df['adr_open']*ratio\n",
    "        merged_df['adr_close'] = merged_df['adr_close']*ratio\n",
    "    else:\n",
    "        ratio = round(merged_df.loc[1,'adr_open']/merged_df.loc[1,'stock_close_usd'])\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open_usd']*ratio\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close_usd']*ratio\n",
    "        \n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive strategy for testing on the SONY adr and stock pair\n",
    "To open a position, we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We buy the stock on the next trading next OPEN for Asian market\n",
    "\n",
    "To close a position,  we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We sell the stock on the next trading next OPEN for Asian market\n",
    "\"\"\"\n",
    "def pairs_trade(merged_df, lookback = 100, cash = 100000, entry = 1, exit = 0, stop_loss = 3):\n",
    "\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    diff_record = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "        # check if there is a px diff between close and stock_close effective\n",
    "        # If index < lookback, we do not place any trade\n",
    "        if index < lookback:\n",
    "            diff_record.append(row['adr_close'] - row['stock_close_usd'])\n",
    "            pass\n",
    "\n",
    "        mean = np.array(diff_record).mean()\n",
    "        std  = np.array(diff_record).std()\n",
    "        \n",
    "        # If we have passed the initial lookback window\n",
    "        # enter the position if diff is significant\n",
    "        if row['adr_close'] - row['stock_close_usd'] > mean + entry * std:\n",
    "            if stock_pos == 0 and adr_pos == 0:\n",
    "                quantity = min(int(0.5*cash/row['adr_close']),int(0.5*cash/row['stock_close_usd']))\n",
    "                if index+1 < len(merged_df):\n",
    "                    adr_pos -= quantity\n",
    "                    cash += quantity*row['adr_close']\n",
    "\n",
    "                    stock_px = merged_df.loc[index+1,'stock_open_usd'] # The actual px we get to trade is on the next day for asian market\n",
    "                    cash -= stock_px*quantity\n",
    "                    stock_pos += quantity\n",
    "                    trade_records.append(\"Opening positions:\\n\")\n",
    "                    trade_records.append(f\"We sold the {quantity} shares of ADR at the price of {row['adr_close']} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We bought the {quantity} shares of underlying stock at the price of {stock_px} USD ({merged_df.loc[index+1,'stock_open']} Japanese dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "\n",
    "\n",
    "        # When do we exit the position?\n",
    "        elif row['adr_close'] - row['stock_close_usd'] < mean + exit * std:\n",
    "            if stock_pos > 0 and adr_pos < 0 : # If we have positions in the stocks, we liquidate the position\n",
    "                if index+1 < len(merged_df):\n",
    "                \n",
    "                    cash -= abs(adr_pos)*row['adr_close']\n",
    "                    cash += stock_pos*merged_df.loc[index+1,'stock_open_usd']\n",
    "                    \n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    trade_records.append(f\"We bought the {stock_pos} shares of ADR at the price of {row['adr_close']} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We sold the {stock_pos} shares of underlying stock at the price of {merged_df.loc[index+1,'stock_open_usd']} USD ({merged_df.loc[index+1,'stock_open']} Japanese dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "                    \n",
    "        # Stop-loss?\n",
    "        elif row['adr_close'] - row['stock_close_usd'] > mean + stop_loss * std:\n",
    "            if stock_pos > 0 and adr_pos < 0 : # If we have positions in the stocks, we liquidate the position\n",
    "                if index+1 < len(merged_df):\n",
    "                \n",
    "                    cash -= abs(adr_pos)*row['adr_close']\n",
    "                    cash += stock_pos*merged_df.loc[index+1,'stock_open_usd']\n",
    "                    \n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    trade_records.append(f\"We bought the {stock_pos} shares of ADR at the price of {row['adr_close']} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We sold the {stock_pos} shares of underlying stock at the price of {merged_df.loc[index+1,'stock_open_usd']} USD ({merged_df.loc[index+1,'stock_open']} Japanese dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "        diff_record.append(row['adr_close'] - row['stock_close_usd'])\n",
    "    final_val = cash + adr_pos*merged_df.loc[len(merged_df) - 1, 'adr_close'] + stock_pos*merged_df.loc[len(merged_df) - 1, 'stock_close_usd'] \n",
    "    ret = (final_val - starting_cash)/starting_cash\n",
    "    \n",
    "    \n",
    "    return ret, trade_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for underlying data of ATHE_ATH from Australia\n",
      "no data for underlying data of IMMP_IMM from Australia\n",
      "no data for underlying data of KZIA_KZA from Australia\n",
      "no data for underlying data of PLL_PLL from Australia\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "\n",
    "mypath = 'eric_jh_data/'\n",
    "countries = ['Australia', 'Japan', 'China']\n",
    "adr_dict = {}\n",
    "return_dict = defaultdict(list)\n",
    "fx_dict = {'Australia':('eric_jh_data/Forex/AUD_USD.csv',0),\n",
    "           'Japan':('eric_jh_data/Forex/USD_JPY.csv',1),\n",
    "           'China':('eric_jh_data/Forex/USD_HKD.csv',1)}\n",
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in adr_names:\n",
    "        merged_df = data_processing(country, adr, fx_dict)\n",
    "        if isinstance(merged_df, pd.core.frame.DataFrame):\n",
    "            ret, trade_records = pairs_trade(merged_df)\n",
    "            return_dict[country].append([adr, ret])\n",
    "            logs = [f'The return of ADR_underlying pairs trading for {adr} from {country} is {ret*100}%\\n']\n",
    "            logs = logs + trade_records \n",
    "            \n",
    "            \n",
    "            fname = f'eric_jh_data/{country}/{adr}/logs.txt'\n",
    "            f = open(fname, 'w')\n",
    "            f.writelines(logs)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because 1 ADR is not necessarily 1 Underlying, we find the ratio to convert the two..\n",
    "ratio =round(merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open'])\n",
    "if ratio >= 1:\n",
    "    merged_df['adr_open'] = merged_df['adr_open']*ratio\n",
    "    merged_df['adr_close'] = merged_df['adr_close']*ratio\n",
    "else:\n",
    "    ratio = round(merged_df.loc[1,'adr_open']/merged_df.loc[1,'stock_close_usd'])\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open_usd']*ratio\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close_usd']*ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Hyperparameters:\n",
    "1. Lookback window\n",
    "2. Entry threshold\n",
    "3. Exit threshold\n",
    "4. Stop-loss threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for underlying data of ATHE_ATH from Australia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2/9 [00:22<01:19, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for underlying data of IMMP_IMM from Australia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:55<00:51, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for underlying data of KZIA_KZA from Australia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 7/9 [01:14<00:23, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for underlying data of PLL_PLL from Australia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:34<00:00, 10.47s/it]\n",
      "100%|██████████| 10/10 [03:11<00:00, 19.14s/it]\n",
      "100%|██████████| 9/9 [02:48<00:00, 18.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "window_grid = [30, 60, 100]\n",
    "entry_grid = [1, 1.5, 2]\n",
    "exit_grid = [-0.5, 0, 0.5]\n",
    "stop_loss_grid = [2.5, 3, 3.5]\n",
    "\n",
    "hps = list(itertools.product(*[window_grid, entry_grid, exit_grid, stop_loss_grid]))\n",
    "\n",
    "mypath = 'eric_jh_data/'\n",
    "countries = ['Australia', 'Japan', 'China']\n",
    "adr_dict = {}\n",
    "return_dict = defaultdict(list)\n",
    "fx_dict = {'Australia':('eric_jh_data/Forex/AUD_USD.csv',0),\n",
    "           'Japan':('eric_jh_data/Forex/USD_JPY.csv',1),\n",
    "           'China':('eric_jh_data/Forex/USD_HKD.csv',1)}\n",
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in tqdm(adr_names):\n",
    "        merged_df = data_processing(country, adr, fx_dict)\n",
    "        if isinstance(merged_df, pd.core.frame.DataFrame):\n",
    "            max_ret = 0\n",
    "            max_ret_hps = (100, 1, 0, 3)\n",
    "            hp_log = []\n",
    "            for hp in hps:\n",
    "                ret = pairs_trade(merged_df, lookback = hp[0], entry = hp[1], exit = hp[2], stop_loss = hp[3])[0]\n",
    "                if ret > max_ret:\n",
    "                    max_ret = ret\n",
    "                    max_ret_hps = hp\n",
    "                hp_log.append(f'Lookback: {hp[0]}\\tEntry: {hp[1]}\\tExit: {hp[2]}\\tStop-loss: {hp[3]}\\tReturn: {ret*100}%\\n')\n",
    "            return_dict[country].append([adr, max_ret, max_ret_hps])\n",
    "            logs = [f'The return of ADR_underlying pairs trading for {adr} from {country} is {max_ret*100}%\\n', \n",
    "                    f'Hyperparameters: Lookback: {max_ret_hps[0]}\\tEntry: {max_ret_hps[1]}\\tExit: {max_ret_hps[2]}\\tStop-loss: {max_ret_hps[3]}\\n']\n",
    "            logs = logs + hp_log\n",
    "            \n",
    "            fname = f'eric_jh_data/{country}/{adr}/hp_log.txt'\n",
    "            f = open(fname, 'w')\n",
    "            f.writelines(logs)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'returns.txt'\n",
    "f = open(fname, 'w')\n",
    "for country in return_dict:\n",
    "    for pairs in return_dict[country]:\n",
    "        string = f'Best return for {pairs[0]} from {country} is {pairs[1] * 100}% with lookback {pairs[2][0]}, entry {pairs[2][1]}, exit {pairs[2][2]}, stop-loss {pairs[2][3]}\\n'\n",
    "        f.writelines(string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Allocation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Old code snippets\n",
    "\n",
    "# Grab the csv data for the stocks\n",
    "adr_path = 'eric_jh_data/Japan/IX_8591/adr.csv'\n",
    "stock_path = 'eric_jh_data/Japan/IX_8591/underlying.csv'\n",
    "fx_path = 'eric_jh_data/Forex/USD_JPY.csv'\n",
    "adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "\n",
    "# Find the ratio between adr and stock:\n",
    "\n",
    "\n",
    "merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n",
    "merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
