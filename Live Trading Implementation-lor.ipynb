{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IB connected to 127.0.0.1:7497 clientId=15>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "util.startLoop()\n",
    "\n",
    "ib = IB()\n",
    "ib.connect('127.0.0.1', 7497, clientId=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime \n",
    "import statsmodels.formula.api as smf \n",
    "from datetime import date, time, datetime, timedelta\n",
    "import seaborn as sns\n",
    "import random\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from ta.trend import *\n",
    "from collections import deque, defaultdict\n",
    "import helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization of hard coded data ###\n",
    "\n",
    "order_books = defaultdict(set)\n",
    "df_ratio = pd.read_csv(\"ratio_dict.csv\", index_col = 0).set_index(\"Pair\")\n",
    "df_global = pd.DataFrame({\"date\":[]})\n",
    "\n",
    "aus_adr_underlying_pairs = [\n",
    "    [\"ATHE\", \"ATH\"],[\"GENE\", \"GTG\"],[\"IMMP\", \"IMM\"],[\"IMRN\",\"IMC\"],[\"JHX\", \"JHX\"],[\"KZIA\", \"KZA\"],\n",
    "    [\"MESO\",\"MSB\"],[\"PLL\", \"PLL\"],[\"WBK\",\"WBC\"]\n",
    "]\n",
    "\n",
    "hk_adr_underlying_pairs = [\n",
    "    [\"ACH\", \"2600\"],[\"BGNE\", \"6160\"],[\"CEA\",\"670\"],[\"HNP\", \"902\"],[\"LFC\", \"2628\"],[\"PTR\", \"857\"],\n",
    "    [\"SHI\", \"338\"],[\"SNP\",\"386\"],[\"ZNH\", \"1055\"]\n",
    "]\n",
    "\n",
    "jpn_adr_underlying_pairs = [\n",
    "    [\"CAJ\", \"7751\"],[\"HMC\",\"7267\"],[\"IX\",\"8591\"],[\"MFG\",\"8411\"],[\"MUFG\",\"8306\"],[\"NMR\",\"8604\"],\n",
    "    [\"SMFG\",\"8316\"],[\"SONY\",\"6758\"],[\"TAK\", \"4502\"],[\"TM\", \"7203\"]\n",
    "]\n",
    "\n",
    "country_info = {\n",
    "    \"Australia\":{\"Currency\": \"AUD\", \n",
    "                \"Exchange\": \"SMART\",\n",
    "                \"Pairs\": aus_adr_underlying_pairs},\n",
    "    \n",
    "    \"Japan\":{\"Currency\": \"JPY\", \n",
    "             \"Exchange\": \"TSEJ\",\n",
    "             \"Pairs\": jpn_adr_underlying_pairs},\n",
    "    \n",
    "    \"HK\":{\"Currency\": \"HKD\", \n",
    "         \"Exchange\": \"SEHK\",\n",
    "         \"Pairs\": hk_adr_underlying_pairs},\n",
    "    \n",
    "}\n",
    "\n",
    "forex_pairs = [(\"AUD\", \"USD\"),  (\"USD\", \"HKD\"), (\"USD\",\"JPY\")]\n",
    "\n",
    "\n",
    "# functions return the market opening time adjusted for DST\n",
    "\n",
    "us_dst = {\n",
    "        2021: (datetime(2021, 3, 14), datetime(2021, 11, 7)),\n",
    "        2020: (datetime(2020, 3, 8),  datetime(2020, 11, 1)),\n",
    "        2019: (datetime(2019, 3, 10), datetime(2019, 11, 3)),\n",
    "        2018: (datetime(2018, 3, 11), datetime(2018, 11, 4)),\n",
    "        2017: (datetime(2017, 3, 12), datetime(2017, 11, 5)),\n",
    "        2016: (datetime(2016, 3, 13), datetime(2016, 11, 6)),\n",
    "        2015: (datetime(2015, 3, 9),  datetime(2015, 11, 2)),\n",
    "    } \n",
    "\n",
    "def next_weekday(date_now):\n",
    "    if date_now.weekday()<4:\n",
    "        return date_now + timedelta(days = 1)\n",
    "    \n",
    "    while date_now.weekday()>3:\n",
    "        date_now += timedelta(days = 1)\n",
    "        \n",
    "    return date_now\n",
    "\n",
    "def next_market_open_day(date_now):\n",
    "    '''\n",
    "    Returns today if Mon - Thurs, returns next Mon if Fri thru Sun\n",
    "    '''\n",
    "    while date_now.weekday()>4:\n",
    "        date_now += timedelta(days = 1)\n",
    "    return date_now\n",
    "\n",
    "def AUS_opening(date_now):\n",
    "    date_adj = next_market_open_day(date_now)\n",
    "    us_start, us_end = us_dst[date_adj.year]\n",
    "    if us_start < date_adj and date_adj < us_end:\n",
    "        return datetime.combine(date_adj,time(10,0)) - timedelta(hours = 14)\n",
    "    else:\n",
    "        return datetime.combine(date_adj, time(10,0)) - timedelta(hours = 15)\n",
    "\n",
    "def AUS_closing(date_now):\n",
    "    open_time = AUS_opening(date_now)\n",
    "    return open_time + timedelta(hours = 6)\n",
    "\n",
    "def HK_opening(date_now):\n",
    "    date_adj = next_market_open_day(date_now)\n",
    "    start, end = us_dst[date_adj.year]\n",
    "    if start < date_adj and date_adj < end:\n",
    "        return datetime.combine(date_adj,time(9,30)) - timedelta(hours = 12)\n",
    "    else:\n",
    "        return datetime.combine(date_adj, time(9,30)) - timedelta(hours = 13)\n",
    "    \n",
    "def HK_closing(date_now):\n",
    "    open_time = HK_opening(date_now)\n",
    "    return open_time + timedelta(hours = 6.5)\n",
    "    \n",
    "def JPN_opening(date_now):\n",
    "    date_now = next_market_open_day(date_now)\n",
    "    start, end = us_dst[date_now.year]\n",
    "    if start < date_now and date_now < end:\n",
    "        return datetime.combine(date_now,time(9,0)) - timedelta(hours = 13)\n",
    "    else:\n",
    "        return datetime.combine(date_now,time(9,0)) - timedelta(hours = 14)\n",
    "    \n",
    "def JPN_closing(date_now):\n",
    "    open_time = JPN_opening(date_now)\n",
    "    return open_time + timedelta(hours = 6)\n",
    "\n",
    "def US_opening(date_now):\n",
    "    return datetime.combine(next_market_open_day(date_now),time(9,30))\n",
    "\n",
    "def US_closing(date_now):\n",
    "    return datetime.combine(next_market_open_day(date_now),time(16,0))\n",
    "\n",
    "##### Initialization of global variables here ###\n",
    "\n",
    "order_books = defaultdict(set)\n",
    "df_ratio = pd.read_csv(\"ratio_dict.csv\", index_col = 0).set_index(\"Pair\")\n",
    "df_global = pd.DataFrame({\"date\":[]})\n",
    "\n",
    "\n",
    "country_info = {\n",
    "    \"Australia\":{\"Currency\": \"AUD\", \n",
    "                \"Exchange\": \"SMART\",\n",
    "                \"Pairs\": aus_adr_underlying_pairs},\n",
    "    \n",
    "    \"Japan\":{\"Currency\": \"JPY\", \n",
    "             \"Exchange\": \"TSEJ\",\n",
    "             \"Pairs\": jpn_adr_underlying_pairs},\n",
    "    \n",
    "    \"China\":{\"Currency\": \"HKD\", \n",
    "         \"Exchange\": \"SEHK\",\n",
    "         \"Pairs\": hk_adr_underlying_pairs},    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data lists, hyperparameters etc\n",
    "\n",
    "path_data = \"live_trading_data/\"\n",
    "df_forex = pd.DataFrame({\"date\":[]})\n",
    "def initialize_forex():\n",
    "    global df_forex, country_info\n",
    "\n",
    "    now = datetime.now()\n",
    "    df_forex = pd.read_csv(f\"{path_data}df_forex.csv\")\n",
    "    df_forex[\"date\"] = [datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S') for date_time in df_forex[\"date\"]]\n",
    "#     pull_head = datetime.combine(max(now-timedelta(days = round(8/5*100)),df_forex[\"date\"].iloc[-1]).date(),time(17,0))\n",
    "    \n",
    "\n",
    "    now = datetime.combine(datetime.now().date(), time(17,5))\n",
    "    df_temp_jpy = pd.DataFrame({\"date\":[]})\n",
    "    df_temp_hkd = pd.DataFrame({\"date\":[]})\n",
    "    df_temp_aud = pd.DataFrame({\"date\":[]})\n",
    "    df_temp_holder = {\n",
    "        \"AUD.USD\" : df_temp_aud,\n",
    "        \"JPY.USD\" : df_temp_jpy,\n",
    "        \"HKD.USD\" : df_temp_hkd\n",
    "    }\n",
    "    pull_head = datetime(2020,11,27)\n",
    "    now = datetime(2020,12,3)\n",
    "    while pull_head < now:\n",
    "        print(pull_head.date())\n",
    "        for currency1, currency2 in forex_pairs:\n",
    "\n",
    "            history = \"2 D\"\n",
    "            freq = \"1 min\"\n",
    "            side = \"BID_ASK\"\n",
    "\n",
    "            forex_contract = Contract(symbol = currency1, secType = \"CASH\", exchange = \"IDEALPRO\", currency = currency2)\n",
    "            ib.qualifyContracts(forex_contract)\n",
    "            try:\n",
    "                df_temp = get_data(forex_contract, history, freq, side, pull_head)    \n",
    "\n",
    "                if currency2 == \"USD\":\n",
    "                    df_temp[f\"{currency1}.{currency2}\"] = (df_temp[\"open\"] + df_temp[\"close\"])/2\n",
    "                    forex_string = f\"{currency1}.{currency2}\"\n",
    "                else:\n",
    "                    df_temp[f\"{currency2}.{currency1}\"] = 2/(df_temp[\"open\"] + df_temp[\"close\"])\n",
    "                    forex_string = f\"{currency2}.{currency1}\"\n",
    "\n",
    "                df_temp[\"date\"] = df_temp[\"date\"].astype('datetime64[s]')\n",
    "\n",
    "                df_temp_holder[forex_string] = pd.merge(df_temp_holder[forex_string], df_temp[[\"date\",forex_string]], how = \"outer\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        pull_head += timedelta(days = 1)\n",
    "    df_temp_2 = pd.merge(df_temp_holder[\"HKD.USD\"],pd.merge(df_temp_holder[\"AUD.USD\"], df_temp_holder[\"JPY.USD\"],  how = \"outer\"), on = \"date\", how = \"outer\")\n",
    "    df_forex = pd.merge(df_forex,df_temp_2, how = \"outer\").drop_duplicates(keep = \"first\").sort_values(\"date\")\n",
    "    #     df_forex.to_csv(f\"{path_data}df_forex.csv\", index = False)\n",
    "    print(\"df_forex initialized\")\n",
    "\n",
    "def save_forex():\n",
    "    global df_forex\n",
    "    df_forex.drop_duplicates(\"date\").sort_values(\"date\")\n",
    "    df_forex.to_csv(f\"{path_data}df_forex.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-27\n",
      "2020-11-28\n",
      "2020-11-29\n",
      "2020-11-30\n",
      "2020-12-01\n",
      "2020-12-02\n",
      "df_forex initialized\n"
     ]
    }
   ],
   "source": [
    "initialize_forex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "[WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "save_forex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>JPY.USD</th>\n",
       "      <th>AUD.USD</th>\n",
       "      <th>HKD.USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>2020-11-09 09:30:00</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.733375</td>\n",
       "      <td>0.128979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2020-11-10 09:30:00</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.727315</td>\n",
       "      <td>0.128962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>2020-11-11 09:30:00</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>0.727560</td>\n",
       "      <td>0.128962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>2020-11-12 09:30:00</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.726525</td>\n",
       "      <td>0.128957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>2020-11-13 09:30:00</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.725035</td>\n",
       "      <td>0.128972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8661</th>\n",
       "      <td>2020-11-16 09:30:00</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.729845</td>\n",
       "      <td>0.128975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10850</th>\n",
       "      <td>2020-11-17 09:30:00</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.730705</td>\n",
       "      <td>0.128989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12983</th>\n",
       "      <td>2020-11-18 09:30:00</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.730240</td>\n",
       "      <td>0.128990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14820</th>\n",
       "      <td>2020-11-19 09:30:00</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>0.726025</td>\n",
       "      <td>0.128970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>2020-11-20 09:30:00</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.731430</td>\n",
       "      <td>0.128989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17670</th>\n",
       "      <td>2020-11-23 09:30:00</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>0.731780</td>\n",
       "      <td>0.128999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>2020-11-24 09:30:00</td>\n",
       "      <td>0.009557</td>\n",
       "      <td>0.732905</td>\n",
       "      <td>0.129010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20520</th>\n",
       "      <td>2020-11-25 09:30:00</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.734150</td>\n",
       "      <td>0.129014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>2020-11-26 09:30:00</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>0.735795</td>\n",
       "      <td>0.129019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23370</th>\n",
       "      <td>2020-11-27 09:30:00</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.129019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174929</th>\n",
       "      <td>2020-11-30 09:30:00</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.737935</td>\n",
       "      <td>0.129007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176354</th>\n",
       "      <td>2020-12-01 09:30:00</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.128998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24795</th>\n",
       "      <td>2020-12-01 09:30:00</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>0.735115</td>\n",
       "      <td>0.128998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26220</th>\n",
       "      <td>2020-12-02 09:30:00</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.735845</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>2020-12-03 09:30:00</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.744145</td>\n",
       "      <td>0.129012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29070</th>\n",
       "      <td>2020-12-04 09:30:00</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.742935</td>\n",
       "      <td>0.129023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30495</th>\n",
       "      <td>2020-12-07 09:30:00</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>0.743070</td>\n",
       "      <td>0.129023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31907</th>\n",
       "      <td>2020-12-08 09:30:00</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.741385</td>\n",
       "      <td>0.129019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33332</th>\n",
       "      <td>2020-12-09 09:30:00</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.747310</td>\n",
       "      <td>0.128996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34757</th>\n",
       "      <td>2020-12-10 09:30:00</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.748960</td>\n",
       "      <td>0.129011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36182</th>\n",
       "      <td>2020-12-11 09:30:00</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>0.754005</td>\n",
       "      <td>0.129016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37607</th>\n",
       "      <td>2020-12-14 09:30:00</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.757205</td>\n",
       "      <td>0.129006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39032</th>\n",
       "      <td>2020-12-15 09:30:00</td>\n",
       "      <td>0.009632</td>\n",
       "      <td>0.753570</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40457</th>\n",
       "      <td>2020-12-16 09:30:00</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.755630</td>\n",
       "      <td>0.129001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41882</th>\n",
       "      <td>2020-12-17 09:30:00</td>\n",
       "      <td>0.009707</td>\n",
       "      <td>0.762060</td>\n",
       "      <td>0.128983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130112</th>\n",
       "      <td>2021-03-17 09:30:00</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.771920</td>\n",
       "      <td>0.128756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131537</th>\n",
       "      <td>2021-03-18 09:30:00</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.776715</td>\n",
       "      <td>0.128788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132962</th>\n",
       "      <td>2021-03-19 09:30:00</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.773135</td>\n",
       "      <td>0.128762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134387</th>\n",
       "      <td>2021-03-22 09:30:00</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.774270</td>\n",
       "      <td>0.128770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135812</th>\n",
       "      <td>2021-03-23 09:30:00</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.767080</td>\n",
       "      <td>0.128757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137237</th>\n",
       "      <td>2021-03-24 09:30:00</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.760590</td>\n",
       "      <td>0.128725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138662</th>\n",
       "      <td>2021-03-25 09:30:00</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.759420</td>\n",
       "      <td>0.128703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140087</th>\n",
       "      <td>2021-03-26 09:30:00</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.762165</td>\n",
       "      <td>0.128709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141512</th>\n",
       "      <td>2021-03-29 09:30:00</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.764350</td>\n",
       "      <td>0.128620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142937</th>\n",
       "      <td>2021-03-30 09:30:00</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.760825</td>\n",
       "      <td>0.128607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144362</th>\n",
       "      <td>2021-03-31 09:30:00</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.760980</td>\n",
       "      <td>0.128632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145787</th>\n",
       "      <td>2021-04-01 09:30:00</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.759450</td>\n",
       "      <td>0.128587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147212</th>\n",
       "      <td>2021-04-02 09:30:00</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0.760605</td>\n",
       "      <td>0.128606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148532</th>\n",
       "      <td>2021-04-05 09:30:00</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.763640</td>\n",
       "      <td>0.128598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149957</th>\n",
       "      <td>2021-04-06 09:30:00</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.763740</td>\n",
       "      <td>0.128579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151382</th>\n",
       "      <td>2021-04-07 09:30:00</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>0.762475</td>\n",
       "      <td>0.128431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152807</th>\n",
       "      <td>2021-04-08 09:30:00</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>0.764200</td>\n",
       "      <td>0.128580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154232</th>\n",
       "      <td>2021-04-09 09:30:00</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.762580</td>\n",
       "      <td>0.128574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155657</th>\n",
       "      <td>2021-04-12 09:30:00</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.762530</td>\n",
       "      <td>0.128622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157082</th>\n",
       "      <td>2021-04-13 09:30:00</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.761935</td>\n",
       "      <td>0.128642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159482</th>\n",
       "      <td>2021-04-14 09:30:00</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.768725</td>\n",
       "      <td>0.128754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159483</th>\n",
       "      <td>2021-04-14 09:30:00</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.768725</td>\n",
       "      <td>0.128754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162332</th>\n",
       "      <td>2021-04-15 09:30:00</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.775380</td>\n",
       "      <td>0.128731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162333</th>\n",
       "      <td>2021-04-15 09:30:00</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.775380</td>\n",
       "      <td>0.128731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165182</th>\n",
       "      <td>2021-04-16 09:30:00</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.774080</td>\n",
       "      <td>0.128672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165183</th>\n",
       "      <td>2021-04-16 09:30:00</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.774080</td>\n",
       "      <td>0.128672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168032</th>\n",
       "      <td>2021-04-19 09:30:00</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.776765</td>\n",
       "      <td>0.128761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168033</th>\n",
       "      <td>2021-04-19 09:30:00</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.776765</td>\n",
       "      <td>0.128761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169907</th>\n",
       "      <td>2021-04-20 09:30:00</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>0.777440</td>\n",
       "      <td>0.128830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171332</th>\n",
       "      <td>2021-04-21 09:30:00</td>\n",
       "      <td>0.009254</td>\n",
       "      <td>0.770945</td>\n",
       "      <td>0.128826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date   JPY.USD   AUD.USD   HKD.USD\n",
       "975    2020-11-09 09:30:00  0.009537  0.733375  0.128979\n",
       "2400   2020-11-10 09:30:00  0.009495  0.727315  0.128962\n",
       "3825   2020-11-11 09:30:00  0.009476  0.727560  0.128962\n",
       "5250   2020-11-12 09:30:00  0.009507  0.726525  0.128957\n",
       "6675   2020-11-13 09:30:00  0.009545  0.725035  0.128972\n",
       "8661   2020-11-16 09:30:00  0.009549  0.729845  0.128975\n",
       "10850  2020-11-17 09:30:00  0.009600  0.730705  0.128989\n",
       "12983  2020-11-18 09:30:00  0.009625  0.730240  0.128990\n",
       "14820  2020-11-19 09:30:00  0.009610  0.726025  0.128970\n",
       "16245  2020-11-20 09:30:00  0.009634  0.731430  0.128989\n",
       "17670  2020-11-23 09:30:00  0.009638  0.731780  0.128999\n",
       "19095  2020-11-24 09:30:00  0.009557  0.732905  0.129010\n",
       "20520  2020-11-25 09:30:00  0.009575  0.734150  0.129014\n",
       "21945  2020-11-26 09:30:00  0.009590  0.735795  0.129019\n",
       "23370  2020-11-27 09:30:00  0.009601  0.738485  0.129019\n",
       "174929 2020-11-30 09:30:00  0.009600  0.737935  0.129007\n",
       "176354 2020-12-01 09:30:00  0.009572  0.735115  0.128998\n",
       "24795  2020-12-01 09:30:00  0.009572  0.735115  0.128998\n",
       "26220  2020-12-02 09:30:00  0.009567  0.735845  0.129000\n",
       "27645  2020-12-03 09:30:00  0.009628  0.744145  0.129012\n",
       "29070  2020-12-04 09:30:00  0.009620  0.742935  0.129023\n",
       "30495  2020-12-07 09:30:00  0.009610  0.743070  0.129023\n",
       "31907  2020-12-08 09:30:00  0.009609  0.741385  0.129019\n",
       "33332  2020-12-09 09:30:00  0.009598  0.747310  0.128996\n",
       "34757  2020-12-10 09:30:00  0.009580  0.748960  0.129011\n",
       "36182  2020-12-11 09:30:00  0.009610  0.754005  0.129016\n",
       "37607  2020-12-14 09:30:00  0.009649  0.757205  0.129006\n",
       "39032  2020-12-15 09:30:00  0.009632  0.753570  0.129000\n",
       "40457  2020-12-16 09:30:00  0.009651  0.755630  0.129001\n",
       "41882  2020-12-17 09:30:00  0.009707  0.762060  0.128983\n",
       "...                    ...       ...       ...       ...\n",
       "130112 2021-03-17 09:30:00  0.009161  0.771920  0.128756\n",
       "131537 2021-03-18 09:30:00  0.009156  0.776715  0.128788\n",
       "132962 2021-03-19 09:30:00  0.009171  0.773135  0.128762\n",
       "134387 2021-03-22 09:30:00  0.009193  0.774270  0.128770\n",
       "135812 2021-03-23 09:30:00  0.009207  0.767080  0.128757\n",
       "137237 2021-03-24 09:30:00  0.009183  0.760590  0.128725\n",
       "138662 2021-03-25 09:30:00  0.009168  0.759420  0.128703\n",
       "140087 2021-03-26 09:30:00  0.009110  0.762165  0.128709\n",
       "141512 2021-03-29 09:30:00  0.009118  0.764350  0.128620\n",
       "142937 2021-03-30 09:30:00  0.009061  0.760825  0.128607\n",
       "144362 2021-03-31 09:30:00  0.009026  0.760980  0.128632\n",
       "145787 2021-04-01 09:30:00  0.009039  0.759450  0.128587\n",
       "147212 2021-04-02 09:30:00  0.009030  0.760605  0.128606\n",
       "148532 2021-04-05 09:30:00  0.009056  0.763640  0.128598\n",
       "149957 2021-04-06 09:30:00  0.009108  0.763740  0.128579\n",
       "151382 2021-04-07 09:30:00  0.009109  0.762475  0.128431\n",
       "152807 2021-04-08 09:30:00  0.009164  0.764200  0.128580\n",
       "154232 2021-04-09 09:30:00  0.009108  0.762580  0.128574\n",
       "155657 2021-04-12 09:30:00  0.009144  0.762530  0.128622\n",
       "157082 2021-04-13 09:30:00  0.009154  0.761935  0.128642\n",
       "159482 2021-04-14 09:30:00  0.009174  0.768725  0.128754\n",
       "159483 2021-04-14 09:30:00  0.009174  0.768725  0.128754\n",
       "162332 2021-04-15 09:30:00  0.009198  0.775380  0.128731\n",
       "162333 2021-04-15 09:30:00  0.009198  0.775380  0.128731\n",
       "165182 2021-04-16 09:30:00  0.009185  0.774080  0.128672\n",
       "165183 2021-04-16 09:30:00  0.009185  0.774080  0.128672\n",
       "168032 2021-04-19 09:30:00  0.009240  0.776765  0.128761\n",
       "168033 2021-04-19 09:30:00  0.009240  0.776765  0.128761\n",
       "169907 2021-04-20 09:30:00  0.009223  0.777440  0.128830\n",
       "171332 2021-04-21 09:30:00  0.009254  0.770945  0.128826\n",
       "\n",
       "[121 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forex[[(date_time.time() == time(9,30)) for date_time in df_forex[\"date\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "[WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "save_forex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forex = df_forex.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_info = {\n",
    "    \"Australia\":{\"Currency\": \"AUD\", \n",
    "                \"Exchange\": \"SMART\",\n",
    "                \"Pairs\": aus_adr_underlying_pairs},\n",
    "    \n",
    "    \"Japan\":{\"Currency\": \"JPY\", \n",
    "             \"Exchange\": \"TSEJ\",\n",
    "             \"Pairs\": jpn_adr_underlying_pairs},\n",
    "    \n",
    "    \"HK\":{\"Currency\": \"HKD\", \n",
    "         \"Exchange\": \"SEHK\",\n",
    "         \"Pairs\": hk_adr_underlying_pairs},\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Store all the historical adr/underlying open and close data\n",
    "\n",
    "#define a function to get IB data. endDate is the last date of the historical data \n",
    "\n",
    "def get_data(contract, history, freq, side, endDate =''):\n",
    "    bar = ib.reqHistoricalData(\n",
    "        contract,\n",
    "        endDateTime = endDate,\n",
    "        durationStr=history,\n",
    "        barSizeSetting= freq,\n",
    "        whatToShow=side,\n",
    "        useRTH=True,\n",
    "        formatDate=1)\n",
    "    return util.df(bar)\n",
    "\n",
    "def pull_asian_close(days = 1):\n",
    "    global df_global, country_info\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    history = f\"{days} D\"\n",
    "    freq = \"1 Day\"\n",
    "    side = 'Trades'\n",
    "    \n",
    "    df_asian_close = pd.DataFrame({\"date\":[]})\n",
    "    for key in country_info.keys():\n",
    "        pairs = country_info[key][\"Pairs\"]\n",
    "        exchange = country_info[key][\"Exchange\"]\n",
    "        currency = country_info[key][\"Currency\"]\n",
    "        \n",
    "        for p in pairs:\n",
    "            underlying = p[1]\n",
    "            contract = Contract(symbol = underlying, secType = 'STK', exchange = exchange, currency = currency)\n",
    "\n",
    "            df = get_data(contract, history, freq, side, endDate =today)\n",
    "            ratio = max(1, df_ratio.loc[f\"{p[0]}_{p[1]}\"][\"stock_num_per_adr\"])\n",
    "            df[f\"underlying_{underlying}_close_per_unit\"] = df[\"close\"] * ratio\n",
    "            df = df.loc[:, [\"date\", \"close\", f\"underlying_{underlying}_close_per_unit\"]]\n",
    "            col_name = \"underlying_\" + underlying + \"_close\"\n",
    "            df = df.rename(columns = {\"close\":col_name})\n",
    "            df_asian_close = pd.merge(df, df_asian_close, how = \"outer\")\n",
    "\n",
    "            \n",
    "    df_global = pd.merge(df_global, df_asian_close,how = \"outer\").sort_values(\"date\")\n",
    "\n",
    "    \n",
    "    \n",
    "def pull_us_close(days = 1):\n",
    "    global df_global, country_info\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    history = f\"{days} D\"\n",
    "    freq = \"1 Day\"\n",
    "    side = 'Trades'\n",
    "    \n",
    "    df_us_close = pd.DataFrame({\"date\":[]})\n",
    "    for key in country_info.keys():\n",
    "        pairs = country_info[key][\"Pairs\"]\n",
    "        exchange = \"SMART\"\n",
    "        currency = \"USD\"\n",
    "        \n",
    "        for p in pairs:\n",
    "            underlying = p[0] # get the ticker of the ADR\n",
    "            contract = Contract(symbol = underlying, secType = 'STK', exchange = exchange, currency = currency)\n",
    "            df = get_data(contract, history, freq, side, endDate ='')\n",
    "            ratio = max(1, df_ratio.loc[f\"{p[0]}_{p[1]}\"][\"adr_num_per_stock\"])\n",
    "            df[f\"adr_{p[0]}_close_per_unit\"] = df[\"close\"] * ratio\n",
    "            df = df.loc[:, [\"date\", \"close\", f\"adr_{p[0]}_close_per_unit\" ]]\n",
    "            col_name = \"adr_\" + underlying + \"_close\"\n",
    "            df = df.rename(columns = {\"close\":col_name})\n",
    "            df_us_close = pd.merge(df, df_us_close, how = 'outer')\n",
    "            \n",
    "    df_global = pd.merge(df_global, df_us_close,how = 'outer').sort_values(\"date\")\n",
    "    \n",
    "def update_df_global_with_forex():\n",
    "    global df_global, df_forex\n",
    "    \n",
    "    us_opens = [datetime.combine(x, time(9,30)) - timedelta(minutes = 5) for x in df_global[\"date\"]]\n",
    "    forex_before_us_opens = df_forex[df_forex[\"date\"].isin(us_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    forex_before_us_opens[\"date\"] = [datetime.date(x) for x in forex_before_us_opens[\"date\"]]\n",
    "    forex_before_us_opens.columns = [\"date\", \"JPY.USD_before_us_open\", \"AUD.USD_before_us_open\", \"HKD.USD_before_us_open\"]\n",
    "\n",
    "    # Add extra date\n",
    "    dates = list(df_global[\"date\"])\n",
    "    last_date = dates[-1]\n",
    "    dates.append(next_weekday(last_date))\n",
    "    aus_opens = [AUS_opening(datetime.combine(x, time(0,0))) - timedelta(minutes = 5) for x in dates]\n",
    "    hk_opens = [HK_opening(datetime.combine(x, time(0,0))) - timedelta(minutes = 5) for x in dates]\n",
    "    jap_opens = [JPN_opening(datetime.combine(x, time(0,0))) - timedelta(minutes = 5) for x in dates]\n",
    "    aus_forex_opens =  df_forex[df_forex[\"date\"].isin(aus_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    hk_forex_opens =  df_forex[df_forex[\"date\"].isin(hk_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    jap_forex_opens =  df_forex[df_forex[\"date\"].isin(jap_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    aus_forex_opens[\"date\"] += timedelta(days = 1)\n",
    "    hk_forex_opens[\"date\"] += timedelta(days = 1)\n",
    "    jap_forex_opens[\"date\"] += timedelta(days = 1)\n",
    "    aus_forex_opens[\"date\"] = [datetime.date(x) for x in aus_forex_opens[\"date\"]]\n",
    "    hk_forex_opens[\"date\"] = [datetime.date(x) for x in hk_forex_opens[\"date\"]]\n",
    "    jap_forex_opens[\"date\"] = [datetime.date(x) for x in jap_forex_opens[\"date\"]]\n",
    "    forex_before_asian_opens = pd.merge(pd.merge(aus_forex_opens[[\"date\", \"AUD.USD\"]], jap_forex_opens[[\"date\", \"JPY.USD\"]], how = \"outer\"),\n",
    "                                        hk_forex_opens[[\"date\", \"HKD.USD\"]], how = \"outer\")\n",
    "    forex_before_asian_opens.columns = [\"date\", \"JPY.USD_before_asian_open\", \"AUD.USD_before_asian_open\", \"HKD.USD_before_asian_open\"]\n",
    "\n",
    "    df_global = pd.merge(df_global, \n",
    "                         pd.merge(forex_before_us_opens, forex_before_asian_opens, how = \"outer\"),\n",
    "                         how = \"outer\").sort_values(\"date\")\n",
    "\n",
    "def pull_forex_data(history = \"2 D\", freq = \"1 min\", side = \"BID_ASK\", end_date = \"\" ):\n",
    "    '''\n",
    "    Updates all three forex pairs\n",
    "    '''\n",
    "    \n",
    "    global df_global, country_info, forex_pairs, test, df_forex\n",
    "\n",
    "    df_temp = pd.DataFrame({\"date\":[]})\n",
    "    for currency1, currency2 in forex_pairs:\n",
    "        contract = Contract(symbol = currency1, secType = 'CASH', exchange = \"IDEALPRO\", currency = currency2)\n",
    "        df = get_data(contract, history, freq, side)\n",
    "\n",
    "        if currency2 == \"USD\":\n",
    "            df[f\"{currency1}.{currency2}\"] = (df[\"open\"] + df[\"close\"])/2\n",
    "            forex_string = f\"{currency1}.{currency2}\"\n",
    "        else:\n",
    "            df[f\"{currency2}.{currency1}\"] = 2/(df[\"open\"] + df[\"close\"])\n",
    "            forex_string = f\"{currency2}.{currency1}\"\n",
    "        df_temp = pd.merge(df_temp, df[['date',forex_string]], how = \"outer\")\n",
    "    \n",
    "    df_forex = pd.merge(df_forex, df_temp, how = \"outer\")\n",
    "    update_df_global_with_forex()\n",
    "    \n",
    "    \n",
    "def convert_price_asian_close():\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert the last Asian prices we pulled before US open into US dollars\n",
    "    Using the most recent forex data\n",
    "    \"\"\"\n",
    "    global df_global, df_forex, df_ratio, country_info\n",
    "    \n",
    "    # We use the last \n",
    "    for key in country_info:\n",
    "        pairs = country_info[key][\"Pairs\"]\n",
    "        for pair in pairs:\n",
    "            underlying_col_name = f\"underlying_{pair[1]}_close\"\n",
    "            pair_name =  pair[0] + \"_\" + pair[1]\n",
    "            ratio = df_ratio.loc[pair_name,\"adr_num_per_stock\"] # Determing number of adr per stock\n",
    "            \n",
    "            forex_col_name = country_info[key][\"Currency\"]+\".USD\"\n",
    "            fx = df_forex.loc[len(df_forex)-1, forex_col_name]\n",
    "            price_in_usd = df_global.loc[len(df_global)-1, underlying_col_name]*ratio*fx\n",
    "            \n",
    "            df_global.at[len(df_global)-1, underlying_col_name] = price_in_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_order(country, security, sectype, side, quantity, price):\n",
    "    global order_books\n",
    "    exchange = country_info[country][\"Exchange\"]\n",
    "    currenct = country_info[country][\"Currency\"]\n",
    "    \n",
    "    # Define order \n",
    "    contract = Contract(symbol = security, secType = 'STK', exchange =exchange, currency = currency)\n",
    "    order = LimitOrder(side,quantity,price)\n",
    "    \n",
    "    # Place the order\n",
    "    msg = ib.placeOrder(contract, order)\n",
    "    orderId = msg.order.orderId\n",
    "    \n",
    "    # Add the orderId to orderbook\n",
    "    name =  security +\"_\"+ sectype\n",
    "    order_books[name].add(orderId)\n",
    "    \n",
    "    \n",
    "\n",
    "def check_open_order(security, sectype = \"underlying\"):\n",
    "    \"\"\"\n",
    "    Check if we have open order for this particular security\n",
    "    Args: \n",
    "    security (str) name of security\n",
    "    sectype(str): takes th evalue either \"adr\" or \"underlying\"\n",
    "    \n",
    "    return: the quantity of open orders (orders that we wanted to trade but not traded) of a particular security\n",
    "    \n",
    "    \"\"\"\n",
    "    global order_books\n",
    "    ct = 0\n",
    "    lookup = security +\"_\"+ sectype\n",
    "    all_orders = order_books[lookup]\n",
    "    open_orders = ib.openOrders()\n",
    "    for o in openOders:\n",
    "        if o.orderId in all_orders:\n",
    "            ct += o.totalQuantity\n",
    "        \n",
    "    return ct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Australia', 'PLL_PLL'): deque([], maxlen=200), ('Australia', 'MESO_MSB'): deque([], maxlen=200), ('Australia', 'GENE_GTG'): deque([], maxlen=200), ('Australia', 'WBK_WBC'): deque([], maxlen=120), ('Australia', 'KZIA_KZA'): deque([], maxlen=120), ('Australia', 'IMMP_IMM'): deque([], maxlen=200), ('Australia', 'IMRN_IMC'): deque([], maxlen=60), ('Australia', 'ATHE_ATH'): deque([], maxlen=120), ('Australia', 'JHX_JHX'): deque([], maxlen=200), ('Japan', 'SONY_6758'): deque([], maxlen=200), ('Japan', 'TAK_4502'): deque([], maxlen=60), ('Japan', 'TM_7203'): deque([], maxlen=200), ('Japan', 'SMFG_8316'): deque([], maxlen=200), ('China', 'BGNE_6160'): deque([], maxlen=120), ('China', 'SNP_386'): deque([], maxlen=200)}\n"
     ]
    }
   ],
   "source": [
    "# Pairs we have chosen to trade\n",
    "trading_limits = {\"Australia\" : 4, \"China\" : 1, \"Japan\" : 3}\n",
    "allocation = {\"Australia\" : 0.3, \"China\" : 0.4, \"Japan\" : 0.3}\n",
    "\n",
    "list_pairs = [(\"Australia\", \"PLL_PLL\"),\n",
    "               (\"Australia\", \"MESO_MSB\"),\n",
    "               (\"Australia\", \"GENE_GTG\"),\n",
    "               (\"Australia\", \"WBK_WBC\"),\n",
    "               (\"Australia\", \"KZIA_KZA\"),\n",
    "               (\"Australia\", \"IMMP_IMM\"),\n",
    "               (\"Australia\", \"IMRN_IMC\"),\n",
    "               (\"Australia\", \"ATHE_ATH\"),\n",
    "               (\"Australia\", \"JHX_JHX\"),\n",
    "               (\"Japan\", \"SONY_6758\"), \n",
    "               (\"Japan\", \"TAK_4502\"),\n",
    "               (\"Japan\", \"TM_7203\"),\n",
    "               (\"Japan\", \"SMFG_8316\"),\n",
    "               (\"China\", \"BGNE_6160\"), \n",
    "               (\"China\", \"SNP_386\")]\n",
    "\n",
    "\n",
    "fname = 'results1_sfx_all.txt'\n",
    "with open(fname, 'r') as f:\n",
    "    is_res = f.readlines()\n",
    "hp = {}\n",
    "for i in range(len(list_pairs)):\n",
    "    hp[list_pairs[i]] = [float(x) for x in is_res[i*5 + 4].split(\"(\")[1].split(\")\")[0].split(\", \")]\n",
    "hp_dict = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    hp_dict[(country, adr)] = {}\n",
    "    hp_dict[(country, adr)][\"lookback\"] = int(hp[(country, adr)][0])\n",
    "    hp_dict[(country, adr)][\"entry\"] = hp[(country, adr)][1]\n",
    "    hp_dict[(country, adr)][\"exit\"] = hp[(country, adr)][2]\n",
    "    hp_dict[(country, adr)][\"stop_loss\"] = hp[(country, adr)][3]\n",
    "    # Fraction of cash allocated to each adr-stock pair\n",
    "    hp_dict[(country, adr)][\"allocation\"] = allocation[country]/trading_limits[country]\n",
    "    hp_dict[(country, adr)][\"original_allocation\"] = allocation[country]/trading_limits[country]\n",
    "\n",
    "diff_record_dict = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    diff_record_dict[(country, adr)] = deque(maxlen = 2*hp_dict[(country, adr)][\"lookback\"])\n",
    "    \n",
    "conditions = {}\n",
    "    for (country, adr) in list_pairs:\n",
    "        conditions[(country, adr)] = {}\n",
    "        conditions[(country, adr)][\"enter_cond1\"] = False\n",
    "        conditions[(country, adr)][\"exit_cond1\"] = False\n",
    "        conditions[(country, adr)][\"enter_cond2\"] = False\n",
    "        conditions[(country, adr)][\"exit_cond2\"] = False\n",
    "\n",
    "    \n",
    "positions = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    positions[(country, adr)] = {}\n",
    "    positions[(country, adr)][\"stock_pos\"] = 0\n",
    "    positions[(country, adr)][\"adr_pos\"] = 0\n",
    "    positions[(country, adr)][\"prev_adr_pos\"] = 0\n",
    "    positions[(country, adr)][\"holding_period\"] = None\n",
    "    positions[(country, adr)][\"trade_type\"] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_z_score():\n",
    "    global df_global, insight_dict, list_pairs\n",
    "    for country, adr in list_pairs:\n",
    "        ticker_ADR, ticker_underlying = adr.split(\"-\")\n",
    "        lookback_window = diff_record_dict[(country,adr)]\n",
    "        # initialize lookback window for each stock\n",
    "        if len(lookback_window) != lookback_window.maxlen:\n",
    "            adr_price = df_global[f\"adr_{ticker_ADR}_close\"]\n",
    "            underlying_price = df_global[f\"adr_{ticker_underlying}_close\"]\n",
    "            us_bef_diff = adr_price - underlying_price\n",
    "            us_aft_diff = (adr_price - underlying_price.shift(-1)).dropna()\n",
    "            i = 1\n",
    "            while diff_record_dict[(country,adr)].maxlen != len(diff_record_dict[(country,adr)]):\n",
    "                lookback_window.appendleft(us_bef_diff.iloc[-i])\n",
    "                lookback_window.appendleft(us_aft_diff.iloc[-i])\n",
    "                i += 1\n",
    "    \n",
    "        # calculate Z score\n",
    "        mean = np.array(lookback_window).mean()\n",
    "        std = np.array(lookback_window).std()\n",
    "        new_diff = adr_price.iloc[-1] - underlying_price.iloc[-1]\n",
    "        zscore = ( new_diff - mean)/std\n",
    "        \n",
    "        # update lookback window\n",
    "        lookback_window.append(new_diff)\n",
    "        \n",
    "        # make trading decisions\n",
    "        if (zscore > hp_dict[(country, adr)][\"entry\"]):\n",
    "            insight_dict[(country, adr)] = \"SHORT\"\n",
    "        elif (zscore < hp_dict[(country, adr)][\"exit\"]):\n",
    "            insight_dict[(country, adr)] = \"EXIT\"\n",
    "        else: \n",
    "            insight_dict[(country, adr)] = \"FLAT\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Peer closed connection\n"
     ]
    }
   ],
   "source": [
    "def execute_trades():\n",
    "    global list_pairs\n",
    "    for (country, adr) in list_pairs:\n",
    "        \n",
    "            current = merged_df.loc[(index - temp_risk_lookback + 1):index].copy()\n",
    "            next_day = merged_df.loc[(index - temp_risk_lookback + 2):(index + 1)].copy()\n",
    "            stock_values = (np.array((current[\"stock_close\"])/np.array(next_day[\"avg_non_us_before\"]))*stock_quantity) \n",
    "            adr_values = np.array(current[\"adr_close\"]*adr_quantity)\n",
    "            sigma, var, max_drawdown_abs = get_risk_statistics(stock_values, adr_values, var_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forex = pd.read_csv(f\"{path_data}df_forex.csv\")\n",
    "df_forex[\"date\"] = [datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S') for date_time in df_forex[\"date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-78eea6cb4d78>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-78eea6cb4d78>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    currency1, currency2, * = country\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "country_info = {\n",
    "    \"Australia\":{\"Currency\": \"AUD\", \n",
    "                \"Exchange\": \"SMART\",\n",
    "                \"Pairs\": aus_adr_underlying_pairs},\n",
    "    \n",
    "    \"Japan\":{\"Currency\": \"JPY\", \n",
    "             \"Exchange\": \"TSEJ\",\n",
    "             \"Pairs\": jpn_adr_underlying_pairs},\n",
    "    \n",
    "    \"HK\":{\"Currency\": \"HKD\", \n",
    "         \"Exchange\": \"SEHK\",\n",
    "         \"Pairs\": hk_adr_underlying_pairs},\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "live_data = {}\n",
    "def pull_live_data():\n",
    "    global live_data, country_info, forex_pairs\n",
    "    \n",
    "    dict_forex = {}\n",
    "    for country in forex_pairs:\n",
    "        currency1, currency2, * = country\n",
    "\n",
    "        history = \"60 S\"\n",
    "        freq = \"1 min\"\n",
    "        side = \"BID_ASK\"\n",
    "\n",
    "        forex_contract = Contract(symbol = currency1, secType = \"CASH\", exchange = \"IDEALPRO\", currency = currency2)\n",
    "        ib.qualifyContracts(forex_contract)\n",
    "        df_temp = get_data(forex_contract, history, freq, side)\n",
    "        \n",
    "        latest_tick = df_temp.iloc[-1]\n",
    "        if currency2 == \"USD\":\n",
    "            live_data[f\"{currency1}.{currency2}\"] = (latest_tick[\"open\"] + latest_tick[\"close\"])/2\n",
    "\n",
    "        else:\n",
    "            live_data[f\"{currency2}.{currency2}\"] = 2/(latest_tick[\"open\"] + latest_tick[\"close\"])\n",
    "            \n",
    "    for country in country_info.keys():\n",
    "        currency = country_info[country][\"Currency\"]\n",
    "        exchange = country_info[country][\"Exchange\"]\n",
    "        pairs_list = country_info[country][\"Pairs\"]\n",
    "        \n",
    "        side = \"Trades\"\n",
    "\n",
    "        for ticker_ADR, ticker_underlying in pairs_list:\n",
    "            contract = Contract(symbol = ticker_ADR, secType = \"STK\", exchange = \"SMART\", currency = currency)\n",
    "            ib.qualifyContracts(contract)\n",
    "            df_temp = get_data(contract, history, freq, side)\n",
    "            latest_tick = df_temp.iloc[-1]\n",
    "            live_data[ticker_ADR] = latest_tick['close'] # NEED TO MULTIPLY BY ADR RATIO\n",
    "            \n",
    "            \n",
    "            contract = Contract(symbol = ticker_underlying, secType = \"STK\", exchange = exchange, currency = currency)\n",
    "            ib.qualifyContracts(contract)\n",
    "            df_temp = get_data(contract, history, freq, side)\n",
    "            latest_tick = df_temp.iloc[-1]\n",
    "            if country == \"Australia\":\n",
    "                live_data[ticker_ADR] = latest_tick['close'] * live_data[\"AUD.USD\"] # NEED TO MULTIPLY BY ADR RATIO\n",
    "            elif country == \"Japan\":\n",
    "                live_data[ticker_ADR] = latest_tick['close'] * live_data[\"JPY.USD\"] # NEED TO MULTIPLY BY ADR RATIO\n",
    "            elif country == \"HK\":\n",
    "                live_data[ticker_ADR] = latest_tick['close'] * live_data[\"HKD.USD\"] # NEED TO MULTIPLY BY ADR RATIO\n",
    "        \n",
    "    \n",
    "    \n",
    "def intraday_trader(HK, AUS, JPN, US):\n",
    "    if HK:\n",
    "        pairs = country_info[\"HK\"][\"Pairs\"]\n",
    "        for ticker_ADR, ticker_underlying in pairs:\n",
    "            # check Z Score of pair\n",
    "            \n",
    "            if (#z score is exit#){\n",
    "                \n",
    "                }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_forex()\n",
    "\n",
    "# update date\n",
    "while True:\n",
    "    # keep track of what day it is\n",
    "    today = datetime.date() # ideally the algorithm starts at 8am in the morning\n",
    "    \n",
    "    # keep track of how many times we pull data for calibration\n",
    "    bef_us_pull = False\n",
    "    bef_us_zscore = False\n",
    "    bef_asia_pull = False\n",
    "    bef_jpn_zscore = False\n",
    "    bef_aus_zscore = False\n",
    "    bef_hk_zscore = False\n",
    "    \n",
    "    # Various Open and Close hours for various markets\n",
    "    \n",
    "    US_open = US_opening(today)\n",
    "    US_close = US_closing(today)\n",
    "    HK_open = HK_opening(today + timedelta(days = 1))\n",
    "    HK_close = HK_closing(today + timedelta(days = 1))\n",
    "    JPN_open = JPN_opening(today + timedelta(days = 1))\n",
    "    JPN_close = JPN_closing(today + timedelta(days = 1))\n",
    "    AUS_open = AUS_opening(today + timedelta(days = 1))\n",
    "    AUS_close = AUS_closing(today + timedelta(days = 1))\n",
    "    \n",
    "    # Keep track if pair is open\n",
    "    \n",
    "    while now < US_close and now < HK_close and now < JPN_close and now < AUS_close:\n",
    "        HK_trading = False\n",
    "        AUS_trading = False\n",
    "        US_trading = False\n",
    "        JPN_trading = False\n",
    "        '''\n",
    "        US Market\n",
    "        '''\n",
    "        # Before US Market Open pull historical data\n",
    "        if not bef_us_pull and now > US_open - timedelta(hours = 1):\n",
    "            bef_us_pull = True\n",
    "            pull_asian_close()\n",
    "            pull_forex_data()\n",
    "            \n",
    "        \n",
    "        # Right before US Market Open for Z Score\n",
    "        if not bef_us_zscore and now > US_open - timedelta(minutes = 4):\n",
    "            bef_us_zscore = True\n",
    "            pull_forex_data()\n",
    "            # Calculate Z score \n",
    "            # make trading decision\n",
    "            convert_price_asian_close()\n",
    "            \n",
    "        if US_open < now and now < US_close:\n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            US_trading = True\n",
    "            pull_live_data()\n",
    "            intraday_trader(HK_trading, AUS_trading, JPN_trading, US_trading)\n",
    "            \n",
    "        if US_close - timedelta(minutes = 10) < now and now < US_close:\n",
    "            # check pending limit orders and liquidate\n",
    "                        \n",
    "        '''\n",
    "        Asian Markets\n",
    "        '''\n",
    "        \n",
    "        # before asian markets open, pull us market close\n",
    "        if not bef_asia_pull and now > US_close + timedelta(hours = 1):\n",
    "            bef_asia_pull = True\n",
    "            pull_us_close()\n",
    "\n",
    "\n",
    "        \n",
    "        # before Hong Kong market open, pull forex to calculate Z score\n",
    "        if not bef_hk_zscore and now > HK_open - timedelta(minutes = 4):\n",
    "            bef_hk_zscore = True\n",
    "            pull_forex_data()\n",
    "            convert_price_asian_close()\n",
    "            # calculate Z score and make decision on trade and size\n",
    "        \n",
    "        # check on Hong Kong Stocks\n",
    "        if HK_open < now and now < HK_close:\n",
    "            HK_trading = True\n",
    "            \n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            \n",
    "        if HK_close - timedelta(minutes = 10) < now and now < HK_close:\n",
    "            # Check pending limit orders and cancel\n",
    "        \n",
    "        # before Japan market open, pull forex to calculate Z score\n",
    "        if not bef_jpn_zscore and now > JPN_opening(today) - timedelta(minutes = 4):\n",
    "            bef_JPN_zscore = True\n",
    "            pull_forex_data()\n",
    "            convert_price_asian_close()\n",
    "            # calculate Z score\n",
    "            # make decision on trade and size\n",
    "        \n",
    "        # check on Japan stocks\n",
    "        if JPN_open < now and now < JPN_close:\n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            JPN_trading = True\n",
    "            \n",
    "        if JPN_close - timedelta(minutes = 10) < now and now < JPN_close:\n",
    "            # Check pending limit orders\n",
    "            \n",
    "        # before Australia market open, pull forex to calculate Z score            \n",
    "        if not bef_aus_zscore and now > AUS_opening(today) - timedelta(minutes = 4):\n",
    "            bef_aus_zscore = True\n",
    "            pull_forex_data()\n",
    "            convert_price_asian_close()\n",
    "        \n",
    "        # check on Australian Stocks\n",
    "        if AUS_open < now and now < AUS_close:\n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            AUS_trading = True\n",
    "            \n",
    "        if AUS_open - timedelta(minutes = 10) < now and now < AUS_close:\n",
    "            # Check pending limit orders         \n",
    "\n",
    "        ib.sleep(120) # Loop every two minutes\n",
    "        now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Contract(secType='STK', conId=13905840, symbol='7751', exchange='TSEJ', primaryExchange='TSEJ', currency='JPY', localSymbol='7751.T', tradingClass='7751')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
