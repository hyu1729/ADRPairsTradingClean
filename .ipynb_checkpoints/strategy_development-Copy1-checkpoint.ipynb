{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "incorporate-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from statsmodels import regression,stats\n",
    "import math\n",
    "import datetime \n",
    "import statsmodels.formula.api as smf \n",
    "from datetime import date, time, datetime, timedelta\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "undefined-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no underlying data for Australia, PLL_PLL\n",
      "There is no underlying data for Australia, ATHE_ATH\n",
      "There is no underlying data for Australia, IMMP_IMM\n",
      "There is no underlying data for Australia, KZIA_KZA\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "\n",
    "mypath = 'eric_jh_data/'\n",
    "countries = ['Australia', 'Japan', 'China']\n",
    "adr_dict = {}\n",
    "return_dict = defaultdict(list)\n",
    "fx_dict = {'Australia':('eric_jh_data/Forex/AUD_USD.csv',0),\n",
    "           'Japan':('eric_jh_data/Forex/USD_JPY.csv',1),\n",
    "           'China':('eric_jh_data/Forex/USD_HKD.csv',1)}\n",
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in adr_names:\n",
    "        merged_df = data_processing(country, adr, fx_dict)\n",
    "        if isinstance(merged_df, pd.core.frame.DataFrame):\n",
    "            ret, trade_records = pairs_trade(merged_df)\n",
    "            return_dict[country].append([adr, ret])\n",
    "            logs = [f'The return of ADR_underlying pairs trading for {adr} from {country} is {ret*100}%\\n']\n",
    "            logs = logs + trade_records \n",
    "            \n",
    "            \n",
    "            fname = f'eric_jh_data/{country}/{adr}/logs.txt'\n",
    "            f = open(fname, 'w')\n",
    "            f.writelines(logs)\n",
    "            f.close()\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ranking-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(country, adr, fx_dict):\n",
    "    adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "    stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "    fx_path = fx_dict[country][0]\n",
    "    fx_type =  fx_dict[country][1]\n",
    "    try:\n",
    "        adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "    except:\n",
    "        print(f\"no data for ADR data of {adr} from {counrty}\")\n",
    "        return None\n",
    "    try:\n",
    "        stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "    except:\n",
    "        print(f\"no data for underlying data of {adr} from {counrty}\")\n",
    "        return None\n",
    "    fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "\n",
    "    merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "    merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n",
    "\n",
    "    if fx_type == 1:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "    else:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']*merged_df['fx_open']\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close']*merged_df['fx_close']\n",
    "\n",
    "    ratio =round(merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open'])\n",
    "    if ratio >= 1:\n",
    "        merged_df['adr_open'] = merged_df['adr_open']*ratio\n",
    "        merged_df['adr_close'] = merged_df['adr_close']*ratio\n",
    "    else:\n",
    "        ratio = round(merged_df.loc[1,'adr_open']/merged_df.loc[1,'stock_close_usd'])\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open_usd']*ratio\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close_usd']*ratio\n",
    "        \n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "elder-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because 1 ADR is not necessarily 1 Underlying, we find the ratio to convert the two..\n",
    "ratio =round(merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open'])\n",
    "if ratio >= 1:\n",
    "    merged_df['adr_open'] = merged_df['adr_open']*ratio\n",
    "    merged_df['adr_close'] = merged_df['adr_close']*ratio\n",
    "else:\n",
    "    ratio = round(merged_df.loc[1,'adr_open']/merged_df.loc[1,'stock_close_usd'])\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open_usd']*ratio\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close_usd']*ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fewer-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['a\\n','b\\n','c\\n']\n",
    "fname = 'text.txt'\n",
    "f = open(fname, \"w\")\n",
    "f.writelines(test)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "strange-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive strategy for testing on the SONY adr and stock pair\n",
    "To open a position, we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We buy the stock on the next trading next OPEN for Asian market\n",
    "\n",
    "To close a position,  we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We sell the stock on the next trading next OPEN for Asian market\n",
    "\"\"\"\n",
    "def pairs_trade(merged_df, lookback = 100, cash = 100000):\n",
    "\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    diff_record = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "        # check if there is a px diff between close and stock_close effective\n",
    "        # If index < lookback, we do not place any trade\n",
    "        if index < lookback:\n",
    "            diff_record.append(row['adr_close'] - row['stock_close_usd'])\n",
    "            pass\n",
    "\n",
    "        # If we have passed the initial lookback window\n",
    "        # enter the position if diff is significant\n",
    "        if row['adr_close'] - row['stock_close_usd'] > np.array(diff_record).mean() + np.array(diff_record).std():\n",
    "            if stock_pos == 0 and adr_pos == 0:\n",
    "                quantity = min(int(0.5*cash/row['adr_close']),int(0.5*cash/row['stock_close_usd']))\n",
    "                if index+1 < len(merged_df):\n",
    "                    adr_pos -= quantity\n",
    "                    cash += quantity*row['adr_close']\n",
    "\n",
    "                    stock_px = merged_df.loc[index+1,'stock_open_usd'] # The actual px we get to trade is on the next day for asian market\n",
    "                    cash -= stock_px*quantity\n",
    "                    stock_pos += quantity\n",
    "                    trade_records.append(\"Opening positions:\\n\")\n",
    "                    trade_records.append(f\"We sold the {quantity} shares of ADR at the price of {row['adr_close']} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We bought the {quantity} shares of underlying stock at the price of {stock_px} USD ({merged_df.loc[index+1,'stock_open']} Japanese dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "\n",
    "\n",
    "        # When do we exit the position?\n",
    "        elif row['adr_close'] - row['stock_close_usd'] < np.array(diff_record).mean():\n",
    "            if stock_pos > 0 and adr_pos < 0 : # If we have positions in the stocks, we liquidate the position\n",
    "                if index+1 < len(merged_df):\n",
    "                \n",
    "                    cash -= abs(adr_pos)*row['adr_close']\n",
    "                    cash += stock_pos*merged_df.loc[index+1,'stock_open_usd']\n",
    "                    \n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    trade_records.append(f\"We bought the {stock_pos} shares of ADR at the price of {row['adr_close']} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We sold the {stock_pos} shares of underlying stock at the price of {merged_df.loc[index+1,'stock_open_usd']} USD ({merged_df.loc[index+1,'stock_open']} Japanese dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "        diff_record.append(row['adr_close'] - row['stock_close_usd'])\n",
    "    final_val = cash + adr_pos*merged_df.loc[len(merged_df) - 1, 'adr_close'] + stock_pos*merged_df.loc[len(merged_df) - 1, 'stock_close_usd'] \n",
    "    ret = (final_val - starting_cash)/starting_cash\n",
    "    \n",
    "    \n",
    "    return ret, trade_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "automated-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110513.74525800598"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Old code snippets\n",
    "\n",
    "# Grab the csv data for the stocks\n",
    "adr_path = 'eric_jh_data/Japan/IX_8591/adr.csv'\n",
    "stock_path = 'eric_jh_data/Japan/IX_8591/underlying.csv'\n",
    "fx_path = 'eric_jh_data/Forex/USD_JPY.csv'\n",
    "adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "\n",
    "# Find the ratio between adr and stock:\n",
    "\n",
    "\n",
    "merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n",
    "merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
