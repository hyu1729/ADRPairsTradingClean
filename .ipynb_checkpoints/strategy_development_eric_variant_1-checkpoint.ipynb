{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from statsmodels import regression,stats\n",
    "import math\n",
    "import datetime \n",
    "import statsmodels.formula.api as smf \n",
    "from datetime import date, time, datetime, timedelta\n",
    "from collections import deque\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio(country, adr, fx_dict):\n",
    "    adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "    stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "    fx_path = fx_dict[country][0]\n",
    "    fx_type =  fx_dict[country][1]\n",
    "    \n",
    "#     Old exception code that we probably don't need anymore\n",
    "#     try:\n",
    "#         adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "#     except:\n",
    "#         print(f\"no data for ADR data of {adr} from {country}\")\n",
    "#         return None\n",
    "#     try:\n",
    "#         stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "#     except:\n",
    "#         print(f\"no data for underlying data of {adr} from {country}\")\n",
    "#         return None\n",
    "\n",
    "    adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "    stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "    \n",
    "    fx_df = pd.read_csv(fx_path, index_col = 0)\n",
    "\n",
    "    merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "    merged_df = pd.merge(merged_df, fx_df)\n",
    "\n",
    "    if fx_type == 1:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']/((merged_df['avg_bid_non_us_at'] + merged_df['avg_ask_non_us_at'])/2)\n",
    "    else:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']*((merged_df['avg_bid_non_us_at'] + merged_df['avg_ask_non_us_at'])/2)\n",
    "        \n",
    "\n",
    "    merged_df[\"ratio\"] = merged_df['stock_open_usd']/merged_df['adr_close']\n",
    "    \n",
    "    ratio_geq_1 = True\n",
    "    \n",
    "    if np.mean(merged_df[\"ratio\"] < 1):\n",
    "        merged_df[\"ratio\"] = 1/merged_df[\"ratio\"]\n",
    "        ratio_geq_1 = False\n",
    "    \n",
    "    return ratio_geq_1, np.round(np.mean(merged_df[\"ratio\"]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Australia, ADR_Stock: JHX_JHX, Estimated Ratio (4 d.p.): 1.003, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Australia, ADR_Stock: PLL_PLL, Estimated Ratio (4 d.p.): 101.803, Implied Ratio (2 s.f.): 100.0\n",
      "Country: Australia, ADR_Stock: GENE_GTG, Estimated Ratio (4 d.p.): 598.1022, Implied Ratio (2 s.f.): 600.0\n",
      "Country: Australia, ADR_Stock: ATHE_ATH, Estimated Ratio (4 d.p.): 60.2569, Implied Ratio (2 s.f.): 60.0\n",
      "Country: Australia, ADR_Stock: IMMP_IMM, Estimated Ratio (4 d.p.): 9.9904, Implied Ratio (2 s.f.): 10.0\n",
      "Country: Australia, ADR_Stock: WBK_WBC, Estimated Ratio (4 d.p.): 1.0002, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Australia, ADR_Stock: KZIA_KZA, Estimated Ratio (4 d.p.): 9.9188, Implied Ratio (2 s.f.): 10.0\n",
      "Country: Australia, ADR_Stock: MESO_MSB, Estimated Ratio (4 d.p.): 5.0133, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Australia, ADR_Stock: IMRN_IMC, Estimated Ratio (4 d.p.): 38.8262, Implied Ratio (2 s.f.): 40.0\n",
      "Country: Japan, ADR_Stock: HMC_7267, Estimated Ratio (4 d.p.): 0.9989, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: CAJ_7751, Estimated Ratio (4 d.p.): 0.9999, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: SMFG_8316, Estimated Ratio (4 d.p.): 5.0006, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Japan, ADR_Stock: IX_8591, Estimated Ratio (4 d.p.): 5.0042, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Japan, ADR_Stock: MFG_8411, Estimated Ratio (4 d.p.): 5.0012, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Japan, ADR_Stock: TAK_4502, Estimated Ratio (4 d.p.): 1.9981, Implied Ratio (2 s.f.): 2.0\n",
      "Country: Japan, ADR_Stock: NMR_8604, Estimated Ratio (4 d.p.): 0.9966, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: MUFG_8306, Estimated Ratio (4 d.p.): 0.9986, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: SONY_6758, Estimated Ratio (4 d.p.): 1.0013, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: TM_7203, Estimated Ratio (4 d.p.): 1.9988, Implied Ratio (2 s.f.): 2.0\n",
      "Country: China, ADR_Stock: CEA_670, Estimated Ratio (4 d.p.): 49.86, Implied Ratio (2 s.f.): 50.0\n",
      "Country: China, ADR_Stock: BGNE_6160, Estimated Ratio (4 d.p.): 12.9268, Implied Ratio (2 s.f.): 13.0\n",
      "Country: China, ADR_Stock: LFC_2628, Estimated Ratio (4 d.p.): 4.9917, Implied Ratio (2 s.f.): 5.0\n",
      "Country: China, ADR_Stock: ZNH_1055, Estimated Ratio (4 d.p.): 49.8956, Implied Ratio (2 s.f.): 50.0\n",
      "Country: China, ADR_Stock: PTR_857, Estimated Ratio (4 d.p.): 99.9536, Implied Ratio (2 s.f.): 100.0\n",
      "Country: China, ADR_Stock: SNP_386, Estimated Ratio (4 d.p.): 100.1859, Implied Ratio (2 s.f.): 100.0\n",
      "Country: China, ADR_Stock: ACH_2600, Estimated Ratio (4 d.p.): 24.9159, Implied Ratio (2 s.f.): 25.0\n",
      "Country: China, ADR_Stock: HNP_902, Estimated Ratio (4 d.p.): 39.872, Implied Ratio (2 s.f.): 40.0\n",
      "Country: China, ADR_Stock: SHI_338, Estimated Ratio (4 d.p.): 100.2263, Implied Ratio (2 s.f.): 100.0\n"
     ]
    }
   ],
   "source": [
    "mypath = 'eric_jh_data/'\n",
    "countries = ['Australia', 'Japan', 'China']\n",
    "adr_dict = {}\n",
    "return_dict = defaultdict(list)\n",
    "fx_dict = {'Australia':('eric_jh_data/Forex/AUD_USD_new.csv',0),\n",
    "           'Japan':('eric_jh_data/Forex/USD_JPY_new.csv',1),\n",
    "           'China':('eric_jh_data/Forex/USD_HKD_new.csv',1)}\n",
    "\n",
    "# Store ratios\n",
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in adr_names:\n",
    "        ratio_geq_1, ratio = get_ratio(country, adr, fx_dict)\n",
    "        if adr == \"ACH_2600\" or adr == \"BGNE_6160\":\n",
    "            rounded_ratio = float('%.2g' % ratio)\n",
    "        else:\n",
    "            rounded_ratio = float('%.1g' % ratio)\n",
    "        print(\"Country: {}, ADR_Stock: {}, Estimated Ratio (4 d.p.): {}, Implied Ratio (2 s.f.): {}\".format(country, adr, ratio, rounded_ratio))\n",
    "        ratio_df = pd.DataFrame({\"ratio_geq_1\" : [ratio_geq_1], \"ratio\" : [rounded_ratio]})\n",
    "        ratio_df.to_csv(f'eric_jh_data/{country}/{adr}/ratio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(country, adr, fx_dict):\n",
    "    adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "    stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "    ratio_path = f'eric_jh_data/{country}/{adr}/ratio.csv'\n",
    "    fx_path = fx_dict[country][0]\n",
    "    fx_type =  fx_dict[country][1]\n",
    "    \n",
    "#     Old exception code that we probably don't need anymore\n",
    "#     try:\n",
    "#         adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "#     except:\n",
    "#         print(f\"no data for ADR data of {adr} from {country}\")\n",
    "#         return None\n",
    "#     try:\n",
    "#         stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "#     except:\n",
    "#         print(f\"no data for underlying data of {adr} from {country}\")\n",
    "#         return None\n",
    "\n",
    "    adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "    stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "    fx_df = pd.read_csv(fx_path, index_col = 0)\n",
    "    ratio_df = pd.read_csv(ratio_path, index_col = 0)\n",
    "\n",
    "    # Invert fx data\n",
    "    if fx_type == 0:\n",
    "        inverted_fx_df = 1/fx_df.iloc[:,[2,1,4,3,6,5,8,7]].copy()\n",
    "        inverted_fx_df.columns = fx_df.columns[1:]\n",
    "        fx_df.iloc[:,1:] = inverted_fx_df\n",
    "    merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "    merged_df = pd.merge(merged_df, fx_df)\n",
    "    ratio_geq_1, ratio = ratio_df[\"ratio_geq_1\"].item(), ratio_df[\"ratio\"].item()\n",
    "\n",
    "#     If ratio >= 1, we shall buy 1 stock, and sell multiple adrs\n",
    "#     If ratio < 1, we shall sell 1 adr, and buy multiple stocks\n",
    "    if ratio_geq_1:\n",
    "        merged_df[\"stock_num_per_unit\"] = 1\n",
    "        merged_df[\"adr_num_per_unit\"] = ratio\n",
    "        merged_df[\"stock_open_per_unit\"] = merged_df[\"stock_open\"]\n",
    "        merged_df[\"stock_close_per_unit\"] = merged_df[\"stock_close\"]\n",
    "        merged_df[\"adr_open_per_unit\"] = merged_df[\"adr_open\"]*ratio\n",
    "        merged_df[\"adr_close_per_unit\"] = merged_df[\"adr_close\"]*ratio\n",
    "    else:\n",
    "        merged_df[\"stock_num_per_unit\"] = ratio\n",
    "        merged_df[\"adr_num_per_unit\"] = 1\n",
    "        merged_df[\"stock_open_per_unit\"] = merged_df[\"stock_open\"]*ratio\n",
    "        merged_df[\"stock_close_per_unit\"] = merged_df[\"stock_close\"]*ratio\n",
    "        merged_df[\"adr_open_per_unit\"] = merged_df[\"adr_open\"]\n",
    "        merged_df[\"adr_close_per_unit\"] = merged_df[\"adr_close\"]\n",
    "        \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in adr_names:\n",
    "        merged_df = data_processing(country, adr, fx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adr_open</th>\n",
       "      <th>adr_close</th>\n",
       "      <th>stock_open</th>\n",
       "      <th>stock_close</th>\n",
       "      <th>avg_bid_non_us_before</th>\n",
       "      <th>avg_ask_non_us_before</th>\n",
       "      <th>avg_bid_non_us_at</th>\n",
       "      <th>avg_ask_non_us_at</th>\n",
       "      <th>avg_bid_us_before</th>\n",
       "      <th>avg_ask_us_before</th>\n",
       "      <th>avg_bid_us_at</th>\n",
       "      <th>avg_ask_us_at</th>\n",
       "      <th>stock_num_per_unit</th>\n",
       "      <th>adr_num_per_unit</th>\n",
       "      <th>stock_open_per_unit</th>\n",
       "      <th>stock_close_per_unit</th>\n",
       "      <th>adr_open_per_unit</th>\n",
       "      <th>adr_close_per_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>37.33</td>\n",
       "      <td>37.57</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.89</td>\n",
       "      <td>7.75132</td>\n",
       "      <td>7.75139</td>\n",
       "      <td>7.75132</td>\n",
       "      <td>7.75139</td>\n",
       "      <td>7.75291</td>\n",
       "      <td>7.75294</td>\n",
       "      <td>7.75291</td>\n",
       "      <td>7.75296</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>279.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>37.33</td>\n",
       "      <td>37.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>37.91</td>\n",
       "      <td>37.68</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.94</td>\n",
       "      <td>7.75205</td>\n",
       "      <td>7.75212</td>\n",
       "      <td>7.75204</td>\n",
       "      <td>7.75212</td>\n",
       "      <td>7.75020</td>\n",
       "      <td>7.75024</td>\n",
       "      <td>7.75020</td>\n",
       "      <td>7.75024</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>289.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>37.91</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>38.09</td>\n",
       "      <td>37.66</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.75033</td>\n",
       "      <td>7.75041</td>\n",
       "      <td>7.75033</td>\n",
       "      <td>7.75041</td>\n",
       "      <td>7.75004</td>\n",
       "      <td>7.75008</td>\n",
       "      <td>7.75004</td>\n",
       "      <td>7.75008</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>288.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>38.09</td>\n",
       "      <td>37.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>37.21</td>\n",
       "      <td>37.64</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.88</td>\n",
       "      <td>7.75030</td>\n",
       "      <td>7.75037</td>\n",
       "      <td>7.75030</td>\n",
       "      <td>7.75037</td>\n",
       "      <td>7.75005</td>\n",
       "      <td>7.75008</td>\n",
       "      <td>7.75005</td>\n",
       "      <td>7.75009</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>287.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>37.21</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>36.87</td>\n",
       "      <td>36.47</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.84</td>\n",
       "      <td>7.75001</td>\n",
       "      <td>7.75007</td>\n",
       "      <td>7.75001</td>\n",
       "      <td>7.75007</td>\n",
       "      <td>7.75014</td>\n",
       "      <td>7.75018</td>\n",
       "      <td>7.75014</td>\n",
       "      <td>7.75018</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>285.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>36.87</td>\n",
       "      <td>36.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  adr_open  adr_close  stock_open  stock_close  \\\n",
       "0  2015-12-01     37.33      37.57        2.79         2.89   \n",
       "1  2015-12-02     37.91      37.68        2.89         2.94   \n",
       "2  2015-12-03     38.09      37.66        2.88         2.96   \n",
       "3  2015-12-04     37.21      37.64        2.87         2.88   \n",
       "4  2015-12-07     36.87      36.47        2.85         2.84   \n",
       "\n",
       "   avg_bid_non_us_before  avg_ask_non_us_before  avg_bid_non_us_at  \\\n",
       "0                7.75132                7.75139            7.75132   \n",
       "1                7.75205                7.75212            7.75204   \n",
       "2                7.75033                7.75041            7.75033   \n",
       "3                7.75030                7.75037            7.75030   \n",
       "4                7.75001                7.75007            7.75001   \n",
       "\n",
       "   avg_ask_non_us_at  avg_bid_us_before  avg_ask_us_before  avg_bid_us_at  \\\n",
       "0            7.75139            7.75291            7.75294        7.75291   \n",
       "1            7.75212            7.75020            7.75024        7.75020   \n",
       "2            7.75041            7.75004            7.75008        7.75004   \n",
       "3            7.75037            7.75005            7.75008        7.75005   \n",
       "4            7.75007            7.75014            7.75018        7.75014   \n",
       "\n",
       "   avg_ask_us_at  stock_num_per_unit  adr_num_per_unit  stock_open_per_unit  \\\n",
       "0        7.75296               100.0                 1                279.0   \n",
       "1        7.75024               100.0                 1                289.0   \n",
       "2        7.75008               100.0                 1                288.0   \n",
       "3        7.75009               100.0                 1                287.0   \n",
       "4        7.75018               100.0                 1                285.0   \n",
       "\n",
       "   stock_close_per_unit  adr_open_per_unit  adr_close_per_unit  \n",
       "0                 289.0              37.33               37.57  \n",
       "1                 294.0              37.91               37.68  \n",
       "2                 296.0              38.09               37.66  \n",
       "3                 288.0              37.21               37.64  \n",
       "4                 284.0              36.87               36.47  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_num_per_unit is how many stocks we would buy for 1 \"unit\" of trade\n",
    "# avg_bid_non_us_before is how much foreign currency we can buy with 1 USD, 1 minute before the Asian market opens\n",
    "# avg_bid_non_us_at is how much foreign currency we can buy with 1 USD, when the Asian market opens\n",
    "# avg_bid_us_before is how much foreign currency we can buy with 1 USD, 1 minute before the US market opens\n",
    "# avg_bid_us_at is how much foreign currency we can buy with 1 USD, when the US market opens\n",
    "# All dates are in local time: so in sequential order, it will go stock_open, stock_close, adr_open, adr_close\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive strategy for testing on the SONY adr and stock pair\n",
    "To open a position, we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We buy the stock on the next trading next OPEN for Asian market\n",
    "\n",
    "To close a position,  we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We sell the stock on the next trading next OPEN for Asian market\n",
    "\"\"\"\n",
    "def pairs_trade(merged_df, lookback = 100, cash = 100000):\n",
    "\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    diff_record_bid = deque(maxlen = lookback)\n",
    "    diff_record_ask = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "        # check if there is a px diff between close and stock_close effective\n",
    "        # If len(diff_record) < lookback, we do not place any trade\n",
    "        if index+1 < len(merged_df):\n",
    "            diff_record_bid.append(row['adr_close_per_unit'] - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before'])\n",
    "            diff_record_ask.append(row['adr_close_per_unit'] - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_ask_non_us_before'])\n",
    "\n",
    "            if len(diff_record_bid) < lookback:\n",
    "                continue\n",
    "\n",
    "            # If we have passed the initial lookback window\n",
    "            # enter the position if diff is significant\n",
    "            if diff_record_bid[-1] > np.array(diff_record_ask).mean() + np.array(diff_record_bid).std():\n",
    "                if stock_pos == 0 and adr_pos == 0:\n",
    "\n",
    "                    units = min(int((0.5*cash)/row['adr_close_per_unit']),int((0.5*cash)/(row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before'])))\n",
    "                    adr_quantity = units*row[\"adr_num_per_unit\"]\n",
    "                    stock_quantity = units*row[\"stock_num_per_unit\"]\n",
    "                    adr_pos -= adr_quantity\n",
    "                    cash += adr_quantity*merged_df.loc[index+1,'adr_open']\n",
    "\n",
    "                    stock_pos += stock_quantity\n",
    "                    stock_px = merged_df.loc[index+1,'stock_open']/merged_df.loc[index+1,'avg_bid_non_us_at']\n",
    "                    # The actual px we get to trade is on the next day for asian market\n",
    "                    cash -= stock_px*stock_quantity\n",
    "\n",
    "                    trade_records.append(\"Opening positions:\\n\")\n",
    "                    trade_records.append(f\"We sold {adr_quantity} shares of ADR at the price of {merged_df.loc[index+1,'adr_open']} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    trade_records.append(f\"We bought {stock_quantity} shares of underlying stock at the price of {stock_px} USD ({merged_df.loc[index+1,'stock_open']} foreign dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "\n",
    "\n",
    "        #     # When do we exit the position?\n",
    "            elif diff_record_ask[-1] < np.array(diff_record_ask).mean():\n",
    "                if stock_pos > 0 and adr_pos < 0 : # If we have positions in the stocks, we liquidate the position\n",
    "                    cash -= abs(adr_pos)*merged_df.loc[index+1,'adr_open']\n",
    "                    stock_px = merged_df.loc[index+1,'stock_open']/merged_df.loc[index+1,'avg_ask_non_us_before']\n",
    "                    cash += stock_pos*stock_px\n",
    "\n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    trade_records.append(f\"We bought {-adr_pos} shares of ADR at the price of {merged_df.loc[index+1,'adr_open']} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    trade_records.append(f\"We sold {stock_pos} shares of underlying stock at the price of {stock_px} USD ({merged_df.loc[index+1,'stock_open']} foreign dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "\n",
    "    final_val = cash + adr_pos*merged_df.loc[len(merged_df) - 1, 'adr_close'] + stock_pos*(merged_df.loc[len(merged_df) - 1, 'stock_close']/merged_df.loc[len(merged_df) - 1, 'avg_ask_us_at'])\n",
    "    ret = (final_val - starting_cash)/starting_cash\n",
    "    \n",
    "    return ret, trade_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Australia, ADR_Stock: JHX_JHX, Return: -11.34%\n",
      "Country: Australia, ADR_Stock: PLL_PLL, Return: 14.13%\n",
      "Country: Australia, ADR_Stock: GENE_GTG, Return: 135.27%\n",
      "Country: Australia, ADR_Stock: ATHE_ATH, Return: 148.42%\n",
      "Country: Australia, ADR_Stock: IMMP_IMM, Return: 24.84%\n",
      "Country: Australia, ADR_Stock: WBK_WBC, Return: -0.26%\n",
      "Country: Australia, ADR_Stock: KZIA_KZA, Return: 124.14%\n",
      "Country: Australia, ADR_Stock: MESO_MSB, Return: 146.05%\n",
      "Country: Australia, ADR_Stock: IMRN_IMC, Return: 49.42%\n",
      "Country: Japan, ADR_Stock: HMC_7267, Return: -1.30%\n",
      "Country: Japan, ADR_Stock: CAJ_7751, Return: 6.10%\n",
      "Country: Japan, ADR_Stock: SMFG_8316, Return: -4.72%\n",
      "Country: Japan, ADR_Stock: IX_8591, Return: 0.14%\n",
      "Country: Japan, ADR_Stock: MFG_8411, Return: 0.76%\n",
      "Country: Japan, ADR_Stock: TAK_4502, Return: -6.31%\n",
      "Country: Japan, ADR_Stock: NMR_8604, Return: 2.64%\n",
      "Country: Japan, ADR_Stock: MUFG_8306, Return: 1.27%\n",
      "Country: Japan, ADR_Stock: SONY_6758, Return: 1.61%\n",
      "Country: Japan, ADR_Stock: TM_7203, Return: 0.35%\n",
      "Country: China, ADR_Stock: CEA_670, Return: 10.62%\n",
      "Country: China, ADR_Stock: BGNE_6160, Return: 0.00%\n",
      "Country: China, ADR_Stock: LFC_2628, Return: 2.22%\n",
      "Country: China, ADR_Stock: ZNH_1055, Return: -6.64%\n",
      "Country: China, ADR_Stock: PTR_857, Return: 2.90%\n",
      "Country: China, ADR_Stock: SNP_386, Return: 1.16%\n",
      "Country: China, ADR_Stock: ACH_2600, Return: 11.68%\n",
      "Country: China, ADR_Stock: HNP_902, Return: 17.99%\n",
      "Country: China, ADR_Stock: SHI_338, Return: 16.72%\n"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in adr_names:\n",
    "        merged_df = data_processing(country, adr, fx_dict)\n",
    "        ret, trade_records = pairs_trade(merged_df)\n",
    "        return_dict[country].append([adr, ret])\n",
    "        logs = [f'The return of ADR_underlying pairs trading for {adr} from {country} is {ret*100}%\\n']\n",
    "        logs = logs + trade_records \n",
    "        fname = f'eric_jh_data/{country}/{adr}/logs1.txt'\n",
    "        f = open(fname, 'w')\n",
    "        f.writelines(logs)\n",
    "        f.close()\n",
    "        print(\"Country: {}, ADR_Stock: {}, Return: {:.2f}%\".format(country, adr, ret*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
