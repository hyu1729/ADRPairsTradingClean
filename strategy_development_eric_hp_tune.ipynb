{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from statsmodels import regression,stats\n",
    "import math\n",
    "import datetime \n",
    "import statsmodels.formula.api as smf \n",
    "from datetime import date, time, datetime, timedelta\n",
    "from collections import deque\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio(country, adr, fx_dict):\n",
    "    adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "    stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "    fx_path = fx_dict[country][0]\n",
    "    fx_type =  fx_dict[country][1]\n",
    "\n",
    "    adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "    stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "    fx_df = pd.read_csv(fx_path, index_col = 0)\n",
    "\n",
    "    merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "    merged_df = pd.merge(merged_df, fx_df)\n",
    "\n",
    "    if fx_type == 1:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']/((merged_df['avg_bid_non_us_at'] + merged_df['avg_ask_non_us_at'])/2)\n",
    "    else:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']*((merged_df['avg_bid_non_us_at'] + merged_df['avg_ask_non_us_at'])/2)\n",
    "    merged_df[\"ratio\"] = merged_df['stock_open_usd']/merged_df['adr_close']\n",
    "    \n",
    "    ratio_geq_1 = True\n",
    "    if np.mean(merged_df[\"ratio\"] < 1):\n",
    "        merged_df[\"ratio\"] = 1/merged_df[\"ratio\"]\n",
    "        ratio_geq_1 = False\n",
    "    \n",
    "    return ratio_geq_1, np.round(np.mean(merged_df[\"ratio\"]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Australia, ADR_Stock: ATHE_ATH, Estimated Ratio (4 d.p.): 59.4889, Implied Ratio (2 s.f.): 60.0\n",
      "Country: Australia, ADR_Stock: GENE_GTG, Estimated Ratio (4 d.p.): 595.5978, Implied Ratio (2 s.f.): 600.0\n",
      "Country: Australia, ADR_Stock: IMMP_IMM, Estimated Ratio (4 d.p.): 9.9082, Implied Ratio (2 s.f.): 10.0\n",
      "Country: Australia, ADR_Stock: IMRN_IMC, Estimated Ratio (4 d.p.): 39.4289, Implied Ratio (2 s.f.): 40.0\n",
      "Country: Australia, ADR_Stock: JHX_JHX, Estimated Ratio (4 d.p.): 1.0043, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Australia, ADR_Stock: KZIA_KZA, Estimated Ratio (4 d.p.): 10.0346, Implied Ratio (2 s.f.): 10.0\n",
      "Country: Australia, ADR_Stock: MESO_MSB, Estimated Ratio (4 d.p.): 5.0155, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Australia, ADR_Stock: PLL_PLL, Estimated Ratio (4 d.p.): 101.5788, Implied Ratio (2 s.f.): 100.0\n",
      "Country: Australia, ADR_Stock: WBK_WBC, Estimated Ratio (4 d.p.): 0.9997, Implied Ratio (2 s.f.): 1.0\n",
      "Country: China, ADR_Stock: ACH_2600, Estimated Ratio (4 d.p.): 24.9288, Implied Ratio (2 s.f.): 25.0\n",
      "Country: China, ADR_Stock: BGNE_6160, Estimated Ratio (4 d.p.): 12.9902, Implied Ratio (2 s.f.): 13.0\n",
      "Country: China, ADR_Stock: CEA_670, Estimated Ratio (4 d.p.): 49.9009, Implied Ratio (2 s.f.): 50.0\n",
      "Country: China, ADR_Stock: HNP_902, Estimated Ratio (4 d.p.): 39.8606, Implied Ratio (2 s.f.): 40.0\n",
      "Country: China, ADR_Stock: LFC_2628, Estimated Ratio (4 d.p.): 4.9939, Implied Ratio (2 s.f.): 5.0\n",
      "Country: China, ADR_Stock: PTR_857, Estimated Ratio (4 d.p.): 99.8525, Implied Ratio (2 s.f.): 100.0\n",
      "Country: China, ADR_Stock: SHI_338, Estimated Ratio (4 d.p.): 99.9224, Implied Ratio (2 s.f.): 100.0\n",
      "Country: China, ADR_Stock: SNP_386, Estimated Ratio (4 d.p.): 99.9663, Implied Ratio (2 s.f.): 100.0\n",
      "Country: China, ADR_Stock: ZNH_1055, Estimated Ratio (4 d.p.): 49.8338, Implied Ratio (2 s.f.): 50.0\n",
      "Country: Japan, ADR_Stock: CAJ_7751, Estimated Ratio (4 d.p.): 0.9995, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: HMC_7267, Estimated Ratio (4 d.p.): 0.9999, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: IX_8591, Estimated Ratio (4 d.p.): 5.0055, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Japan, ADR_Stock: MFG_8411, Estimated Ratio (4 d.p.): 4.9999, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Japan, ADR_Stock: MUFG_8306, Estimated Ratio (4 d.p.): 0.9995, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: NMR_8604, Estimated Ratio (4 d.p.): 0.9998, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: SMFG_8316, Estimated Ratio (4 d.p.): 5.0032, Implied Ratio (2 s.f.): 5.0\n",
      "Country: Japan, ADR_Stock: SONY_6758, Estimated Ratio (4 d.p.): 1.0009, Implied Ratio (2 s.f.): 1.0\n",
      "Country: Japan, ADR_Stock: TAK_4502, Estimated Ratio (4 d.p.): 2.001, Implied Ratio (2 s.f.): 2.0\n",
      "Country: Japan, ADR_Stock: TM_7203, Estimated Ratio (4 d.p.): 2.0001, Implied Ratio (2 s.f.): 2.0\n"
     ]
    }
   ],
   "source": [
    "mypath = 'eric_jh_data/'\n",
    "countries = sorted(['Australia', 'Japan', 'China'])\n",
    "fx_dict = {'Australia':('eric_jh_data/Forex/AUD_USD_new.csv',0),\n",
    "           'Japan':('eric_jh_data/Forex/USD_JPY_new.csv',1),\n",
    "           'China':('eric_jh_data/Forex/USD_HKD_new.csv',1)}\n",
    "\n",
    "list_pairs = []\n",
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    for adr in sorted(adr_names):\n",
    "        list_pairs.append((country, adr))\n",
    "        \n",
    "# Store ratios\n",
    "for (country, adr) in list_pairs:\n",
    "    ratio_geq_1, ratio = get_ratio(country, adr, fx_dict)\n",
    "    if adr == \"ACH_2600\" or adr == \"BGNE_6160\":\n",
    "        rounded_ratio = float('%.2g' % ratio)\n",
    "    else:\n",
    "        rounded_ratio = float('%.1g' % ratio)\n",
    "    print(\"Country: {}, ADR_Stock: {}, Estimated Ratio (4 d.p.): {}, Implied Ratio (2 s.f.): {}\".format(country, adr, ratio, rounded_ratio))\n",
    "    ratio_df = pd.DataFrame({\"ratio_geq_1\" : [ratio_geq_1], \"ratio\" : [rounded_ratio]})\n",
    "    ratio_df.to_csv(f'eric_jh_data/{country}/{adr}/ratio.csv')\n",
    "        \n",
    "# This shows the empircally estimated ratio, and the implied ratio we shall assume.\n",
    "# These values corroborate with the select few we checked online, like GENE_GTG and BGNE_6160."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(country, adr, fx_dict, forex_bps = 10, adjust_forex_expense = True):\n",
    "    adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "    stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "    ratio_path = f'eric_jh_data/{country}/{adr}/ratio.csv'\n",
    "    fx_path = fx_dict[country][0]\n",
    "    fx_type =  fx_dict[country][1]\n",
    "\n",
    "    adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open', 'volume' : 'adr_volume'})\n",
    "    stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open', 'volume' : 'stock_volume'})\n",
    "    fx_df = pd.read_csv(fx_path, index_col = 0)\n",
    "    ratio_df = pd.read_csv(ratio_path, index_col = 0)\n",
    "\n",
    "    # Invert fx data so that all prices are reflected in USD\n",
    "    if fx_type == 0:\n",
    "        inverted_fx_df = 1/fx_df.iloc[:,[2,1,4,3,6,5,8,7]].copy()\n",
    "        inverted_fx_df.columns = fx_df.columns[1:]\n",
    "        fx_df.iloc[:,1:] = inverted_fx_df\n",
    "    merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close', 'adr_volume']], stock_df.loc[:,['date', 'stock_open','stock_close', 'stock_volume']])\n",
    "    merged_df = pd.merge(merged_df, fx_df)\n",
    "    ratio_geq_1, ratio = ratio_df[\"ratio_geq_1\"].item(), ratio_df[\"ratio\"].item()\n",
    "\n",
    "#     ratio is (stock price in USD)/(ADR price)\n",
    "#     If ratio >= 1, we shall buy 1 stock, and sell multiple adrs\n",
    "#     If ratio < 1, we shall sell 1 adr, and buy multiple stocks\n",
    "    if ratio_geq_1:\n",
    "        merged_df[\"stock_num_per_unit\"] = 1\n",
    "        merged_df[\"adr_num_per_unit\"] = ratio\n",
    "        merged_df[\"stock_open_per_unit\"] = merged_df[\"stock_open\"]\n",
    "        merged_df[\"stock_close_per_unit\"] = merged_df[\"stock_close\"]\n",
    "        merged_df[\"adr_open_per_unit\"] = merged_df[\"adr_open\"]*ratio\n",
    "        merged_df[\"adr_close_per_unit\"] = merged_df[\"adr_close\"]*ratio\n",
    "    else:\n",
    "        merged_df[\"stock_num_per_unit\"] = ratio\n",
    "        merged_df[\"adr_num_per_unit\"] = 1\n",
    "        merged_df[\"stock_open_per_unit\"] = merged_df[\"stock_open\"]*ratio\n",
    "        merged_df[\"stock_close_per_unit\"] = merged_df[\"stock_close\"]*ratio\n",
    "        merged_df[\"adr_open_per_unit\"] = merged_df[\"adr_open\"]\n",
    "        merged_df[\"adr_close_per_unit\"] = merged_df[\"adr_close\"]    \n",
    "    \n",
    "    if adjust_forex_expense:\n",
    "        # Added expense for trading small amounts in forex market\n",
    "        forex_bid_multiplier = 1 - 0.0001*forex_bps\n",
    "        forex_ask_multiplier = 1 + 0.0001*forex_bps\n",
    "        merged_df.loc[:,merged_df.columns.str.contains(\"bid\")] *= forex_bid_multiplier\n",
    "        merged_df.loc[:,merged_df.columns.str.contains(\"ask\")] *= forex_ask_multiplier\n",
    "        \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adr_open</th>\n",
       "      <th>adr_close</th>\n",
       "      <th>adr_volume</th>\n",
       "      <th>stock_open</th>\n",
       "      <th>stock_close</th>\n",
       "      <th>stock_volume</th>\n",
       "      <th>avg_bid_non_us_before</th>\n",
       "      <th>avg_ask_non_us_before</th>\n",
       "      <th>avg_bid_non_us_at</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_bid_us_before</th>\n",
       "      <th>avg_ask_us_before</th>\n",
       "      <th>avg_bid_us_at</th>\n",
       "      <th>avg_ask_us_at</th>\n",
       "      <th>stock_num_per_unit</th>\n",
       "      <th>adr_num_per_unit</th>\n",
       "      <th>stock_open_per_unit</th>\n",
       "      <th>stock_close_per_unit</th>\n",
       "      <th>adr_open_per_unit</th>\n",
       "      <th>adr_close_per_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>153.60</td>\n",
       "      <td>154.16</td>\n",
       "      <td>1739</td>\n",
       "      <td>8694.0</td>\n",
       "      <td>8423.0</td>\n",
       "      <td>6471600</td>\n",
       "      <td>110.649240</td>\n",
       "      <td>110.872762</td>\n",
       "      <td>110.634255</td>\n",
       "      <td>...</td>\n",
       "      <td>110.518371</td>\n",
       "      <td>110.740630</td>\n",
       "      <td>110.515374</td>\n",
       "      <td>110.737627</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17388.0</td>\n",
       "      <td>16846.0</td>\n",
       "      <td>153.60</td>\n",
       "      <td>154.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>154.16</td>\n",
       "      <td>155.38</td>\n",
       "      <td>1838</td>\n",
       "      <td>8495.0</td>\n",
       "      <td>8461.0</td>\n",
       "      <td>3331600</td>\n",
       "      <td>110.560329</td>\n",
       "      <td>110.783673</td>\n",
       "      <td>110.561328</td>\n",
       "      <td>...</td>\n",
       "      <td>110.322567</td>\n",
       "      <td>110.544434</td>\n",
       "      <td>110.314575</td>\n",
       "      <td>110.537427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16990.0</td>\n",
       "      <td>16922.0</td>\n",
       "      <td>154.16</td>\n",
       "      <td>155.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>153.10</td>\n",
       "      <td>153.65</td>\n",
       "      <td>2494</td>\n",
       "      <td>8570.0</td>\n",
       "      <td>8366.0</td>\n",
       "      <td>4527100</td>\n",
       "      <td>110.080809</td>\n",
       "      <td>110.302192</td>\n",
       "      <td>110.086803</td>\n",
       "      <td>...</td>\n",
       "      <td>109.666224</td>\n",
       "      <td>109.886777</td>\n",
       "      <td>109.680210</td>\n",
       "      <td>109.900791</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17140.0</td>\n",
       "      <td>16732.0</td>\n",
       "      <td>153.10</td>\n",
       "      <td>153.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>154.84</td>\n",
       "      <td>154.70</td>\n",
       "      <td>1282</td>\n",
       "      <td>8474.0</td>\n",
       "      <td>8487.0</td>\n",
       "      <td>4666500</td>\n",
       "      <td>109.685205</td>\n",
       "      <td>109.905796</td>\n",
       "      <td>109.680210</td>\n",
       "      <td>...</td>\n",
       "      <td>109.671219</td>\n",
       "      <td>109.891782</td>\n",
       "      <td>109.676214</td>\n",
       "      <td>109.896787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16948.0</td>\n",
       "      <td>16974.0</td>\n",
       "      <td>154.84</td>\n",
       "      <td>154.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>154.35</td>\n",
       "      <td>153.38</td>\n",
       "      <td>1504</td>\n",
       "      <td>8498.0</td>\n",
       "      <td>8418.0</td>\n",
       "      <td>3617000</td>\n",
       "      <td>109.744146</td>\n",
       "      <td>109.964855</td>\n",
       "      <td>109.759131</td>\n",
       "      <td>...</td>\n",
       "      <td>109.007883</td>\n",
       "      <td>109.227118</td>\n",
       "      <td>109.011879</td>\n",
       "      <td>109.231122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16996.0</td>\n",
       "      <td>16836.0</td>\n",
       "      <td>154.35</td>\n",
       "      <td>153.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  adr_open  adr_close  adr_volume  stock_open  stock_close  \\\n",
       "1408  2021-04-01    153.60     154.16        1739      8694.0       8423.0   \n",
       "1409  2021-04-05    154.16     155.38        1838      8495.0       8461.0   \n",
       "1410  2021-04-06    153.10     153.65        2494      8570.0       8366.0   \n",
       "1411  2021-04-07    154.84     154.70        1282      8474.0       8487.0   \n",
       "1412  2021-04-08    154.35     153.38        1504      8498.0       8418.0   \n",
       "\n",
       "      stock_volume  avg_bid_non_us_before  avg_ask_non_us_before  \\\n",
       "1408       6471600             110.649240             110.872762   \n",
       "1409       3331600             110.560329             110.783673   \n",
       "1410       4527100             110.080809             110.302192   \n",
       "1411       4666500             109.685205             109.905796   \n",
       "1412       3617000             109.744146             109.964855   \n",
       "\n",
       "      avg_bid_non_us_at  ...  avg_bid_us_before  avg_ask_us_before  \\\n",
       "1408         110.634255  ...         110.518371         110.740630   \n",
       "1409         110.561328  ...         110.322567         110.544434   \n",
       "1410         110.086803  ...         109.666224         109.886777   \n",
       "1411         109.680210  ...         109.671219         109.891782   \n",
       "1412         109.759131  ...         109.007883         109.227118   \n",
       "\n",
       "      avg_bid_us_at  avg_ask_us_at  stock_num_per_unit  adr_num_per_unit  \\\n",
       "1408     110.515374     110.737627                 2.0                 1   \n",
       "1409     110.314575     110.537427                 2.0                 1   \n",
       "1410     109.680210     109.900791                 2.0                 1   \n",
       "1411     109.676214     109.896787                 2.0                 1   \n",
       "1412     109.011879     109.231122                 2.0                 1   \n",
       "\n",
       "      stock_open_per_unit  stock_close_per_unit  adr_open_per_unit  \\\n",
       "1408              17388.0               16846.0             153.60   \n",
       "1409              16990.0               16922.0             154.16   \n",
       "1410              17140.0               16732.0             153.10   \n",
       "1411              16948.0               16974.0             154.84   \n",
       "1412              16996.0               16836.0             154.35   \n",
       "\n",
       "      adr_close_per_unit  \n",
       "1408              154.16  \n",
       "1409              155.38  \n",
       "1410              153.65  \n",
       "1411              154.70  \n",
       "1412              153.38  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_num_per_unit is how many stocks we would buy for 1 \"unit\" of trade\n",
    "# avg_bid_non_us_before is how much foreign currency we can buy with 1 USD, 1 minute before the Asian market opens\n",
    "# avg_bid_non_us_at is how much foreign currency we can buy with 1 USD, when the Asian market opens\n",
    "# avg_bid_us_before is how much foreign currency we can buy with 1 USD, 1 minute before the US market opens\n",
    "# avg_bid_us_at is how much foreign currency we can buy with 1 USD, when the US market opens\n",
    "# All dates are in local time: so in sequential order (for each row), it will go stock_open, stock_close, adr_open, adr_close\n",
    "merged_df = data_processing(country, adr, fx_dict)\n",
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_drawdown(portfolio_values, method = \"percentage\"):\n",
    "    peak, trough = portfolio_values[0], portfolio_values[0]\n",
    "    max_drawdown = 0\n",
    "    for i in range(1, len(portfolio_values)):\n",
    "        if portfolio_values[i] < trough:\n",
    "            trough = portfolio_values[i]\n",
    "            if method == \"percentage\":\n",
    "                max_drawdown = max(max_drawdown, (peak - trough)/peak)\n",
    "            else:\n",
    "                max_drawdown = max(max_drawdown, peak - trough)\n",
    "        elif portfolio_values[i] > peak:\n",
    "            peak, trough = portfolio_values[i], portfolio_values[i]\n",
    "    return max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_statistics(stock_values, adr_values, var_ci):\n",
    "    port_stock = stock_values - adr_values\n",
    "    port = pd.DataFrame(data = port_stock)\n",
    "    port_diff = port - port.shift(1)\n",
    "    pnl = pd.DataFrame(port_diff).dropna()\n",
    "    sigma = pnl.std()[0]\n",
    "    pnl['pct_rank'] = pnl.rank(pct=True)\n",
    "    pnl.columns =['daily_pl', 'pct_rank']\n",
    "    var = abs(pnl[pnl.pct_rank< 1-var_ci].daily_pl.max())\n",
    "    max_drawdown_abs = calc_max_drawdown(port_stock, \"absolute\")\n",
    "    return sigma, var, max_drawdown_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adr_open</th>\n",
       "      <th>adr_close</th>\n",
       "      <th>adr_volume</th>\n",
       "      <th>stock_open</th>\n",
       "      <th>stock_close</th>\n",
       "      <th>stock_volume</th>\n",
       "      <th>avg_bid_non_us_before</th>\n",
       "      <th>avg_ask_non_us_before</th>\n",
       "      <th>avg_bid_non_us_at</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_bid_us_before</th>\n",
       "      <th>avg_ask_us_before</th>\n",
       "      <th>avg_bid_us_at</th>\n",
       "      <th>avg_ask_us_at</th>\n",
       "      <th>stock_num_per_unit</th>\n",
       "      <th>adr_num_per_unit</th>\n",
       "      <th>stock_open_per_unit</th>\n",
       "      <th>stock_close_per_unit</th>\n",
       "      <th>adr_open_per_unit</th>\n",
       "      <th>adr_close_per_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>137.67</td>\n",
       "      <td>137.56</td>\n",
       "      <td>2466</td>\n",
       "      <td>8326.0</td>\n",
       "      <td>8248.0</td>\n",
       "      <td>6695800</td>\n",
       "      <td>120.082797</td>\n",
       "      <td>120.327207</td>\n",
       "      <td>120.078801</td>\n",
       "      <td>...</td>\n",
       "      <td>120.053826</td>\n",
       "      <td>120.296176</td>\n",
       "      <td>120.048831</td>\n",
       "      <td>120.291171</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16652.0</td>\n",
       "      <td>16496.0</td>\n",
       "      <td>137.67</td>\n",
       "      <td>137.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>138.69</td>\n",
       "      <td>138.66</td>\n",
       "      <td>1232</td>\n",
       "      <td>8216.0</td>\n",
       "      <td>8285.0</td>\n",
       "      <td>4276300</td>\n",
       "      <td>119.932947</td>\n",
       "      <td>120.177057</td>\n",
       "      <td>119.941938</td>\n",
       "      <td>...</td>\n",
       "      <td>119.317563</td>\n",
       "      <td>119.559440</td>\n",
       "      <td>119.319561</td>\n",
       "      <td>119.560441</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16432.0</td>\n",
       "      <td>16570.0</td>\n",
       "      <td>138.69</td>\n",
       "      <td>138.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>139.23</td>\n",
       "      <td>139.08</td>\n",
       "      <td>1313</td>\n",
       "      <td>8250.0</td>\n",
       "      <td>8273.0</td>\n",
       "      <td>4569400</td>\n",
       "      <td>119.331549</td>\n",
       "      <td>119.574455</td>\n",
       "      <td>119.354526</td>\n",
       "      <td>...</td>\n",
       "      <td>119.155725</td>\n",
       "      <td>119.395276</td>\n",
       "      <td>119.140740</td>\n",
       "      <td>119.381262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>16546.0</td>\n",
       "      <td>139.23</td>\n",
       "      <td>139.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>139.05</td>\n",
       "      <td>138.98</td>\n",
       "      <td>1450</td>\n",
       "      <td>8285.0</td>\n",
       "      <td>8309.0</td>\n",
       "      <td>4242800</td>\n",
       "      <td>119.025855</td>\n",
       "      <td>119.268149</td>\n",
       "      <td>119.023857</td>\n",
       "      <td>...</td>\n",
       "      <td>118.944936</td>\n",
       "      <td>119.184065</td>\n",
       "      <td>118.949931</td>\n",
       "      <td>119.190071</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16570.0</td>\n",
       "      <td>16618.0</td>\n",
       "      <td>139.05</td>\n",
       "      <td>138.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>138.99</td>\n",
       "      <td>138.43</td>\n",
       "      <td>2017</td>\n",
       "      <td>8309.0</td>\n",
       "      <td>8297.0</td>\n",
       "      <td>7016400</td>\n",
       "      <td>118.927953</td>\n",
       "      <td>119.169050</td>\n",
       "      <td>118.923957</td>\n",
       "      <td>...</td>\n",
       "      <td>119.011869</td>\n",
       "      <td>119.252133</td>\n",
       "      <td>119.006874</td>\n",
       "      <td>119.247128</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16618.0</td>\n",
       "      <td>16594.0</td>\n",
       "      <td>138.99</td>\n",
       "      <td>138.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>153.60</td>\n",
       "      <td>154.16</td>\n",
       "      <td>1739</td>\n",
       "      <td>8694.0</td>\n",
       "      <td>8423.0</td>\n",
       "      <td>6471600</td>\n",
       "      <td>110.649240</td>\n",
       "      <td>110.872762</td>\n",
       "      <td>110.634255</td>\n",
       "      <td>...</td>\n",
       "      <td>110.518371</td>\n",
       "      <td>110.740630</td>\n",
       "      <td>110.515374</td>\n",
       "      <td>110.737627</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17388.0</td>\n",
       "      <td>16846.0</td>\n",
       "      <td>153.60</td>\n",
       "      <td>154.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>154.16</td>\n",
       "      <td>155.38</td>\n",
       "      <td>1838</td>\n",
       "      <td>8495.0</td>\n",
       "      <td>8461.0</td>\n",
       "      <td>3331600</td>\n",
       "      <td>110.560329</td>\n",
       "      <td>110.783673</td>\n",
       "      <td>110.561328</td>\n",
       "      <td>...</td>\n",
       "      <td>110.322567</td>\n",
       "      <td>110.544434</td>\n",
       "      <td>110.314575</td>\n",
       "      <td>110.537427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16990.0</td>\n",
       "      <td>16922.0</td>\n",
       "      <td>154.16</td>\n",
       "      <td>155.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>153.10</td>\n",
       "      <td>153.65</td>\n",
       "      <td>2494</td>\n",
       "      <td>8570.0</td>\n",
       "      <td>8366.0</td>\n",
       "      <td>4527100</td>\n",
       "      <td>110.080809</td>\n",
       "      <td>110.302192</td>\n",
       "      <td>110.086803</td>\n",
       "      <td>...</td>\n",
       "      <td>109.666224</td>\n",
       "      <td>109.886777</td>\n",
       "      <td>109.680210</td>\n",
       "      <td>109.900791</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17140.0</td>\n",
       "      <td>16732.0</td>\n",
       "      <td>153.10</td>\n",
       "      <td>153.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>154.84</td>\n",
       "      <td>154.70</td>\n",
       "      <td>1282</td>\n",
       "      <td>8474.0</td>\n",
       "      <td>8487.0</td>\n",
       "      <td>4666500</td>\n",
       "      <td>109.685205</td>\n",
       "      <td>109.905796</td>\n",
       "      <td>109.680210</td>\n",
       "      <td>...</td>\n",
       "      <td>109.671219</td>\n",
       "      <td>109.891782</td>\n",
       "      <td>109.676214</td>\n",
       "      <td>109.896787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16948.0</td>\n",
       "      <td>16974.0</td>\n",
       "      <td>154.84</td>\n",
       "      <td>154.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>154.35</td>\n",
       "      <td>153.38</td>\n",
       "      <td>1504</td>\n",
       "      <td>8498.0</td>\n",
       "      <td>8418.0</td>\n",
       "      <td>3617000</td>\n",
       "      <td>109.744146</td>\n",
       "      <td>109.964855</td>\n",
       "      <td>109.759131</td>\n",
       "      <td>...</td>\n",
       "      <td>109.007883</td>\n",
       "      <td>109.227118</td>\n",
       "      <td>109.011879</td>\n",
       "      <td>109.231122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16996.0</td>\n",
       "      <td>16836.0</td>\n",
       "      <td>154.35</td>\n",
       "      <td>153.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1413 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  adr_open  adr_close  adr_volume  stock_open  stock_close  \\\n",
       "0     2015-04-13    137.67     137.56        2466      8326.0       8248.0   \n",
       "1     2015-04-14    138.69     138.66        1232      8216.0       8285.0   \n",
       "2     2015-04-15    139.23     139.08        1313      8250.0       8273.0   \n",
       "3     2015-04-16    139.05     138.98        1450      8285.0       8309.0   \n",
       "4     2015-04-17    138.99     138.43        2017      8309.0       8297.0   \n",
       "...          ...       ...        ...         ...         ...          ...   \n",
       "1408  2021-04-01    153.60     154.16        1739      8694.0       8423.0   \n",
       "1409  2021-04-05    154.16     155.38        1838      8495.0       8461.0   \n",
       "1410  2021-04-06    153.10     153.65        2494      8570.0       8366.0   \n",
       "1411  2021-04-07    154.84     154.70        1282      8474.0       8487.0   \n",
       "1412  2021-04-08    154.35     153.38        1504      8498.0       8418.0   \n",
       "\n",
       "      stock_volume  avg_bid_non_us_before  avg_ask_non_us_before  \\\n",
       "0          6695800             120.082797             120.327207   \n",
       "1          4276300             119.932947             120.177057   \n",
       "2          4569400             119.331549             119.574455   \n",
       "3          4242800             119.025855             119.268149   \n",
       "4          7016400             118.927953             119.169050   \n",
       "...            ...                    ...                    ...   \n",
       "1408       6471600             110.649240             110.872762   \n",
       "1409       3331600             110.560329             110.783673   \n",
       "1410       4527100             110.080809             110.302192   \n",
       "1411       4666500             109.685205             109.905796   \n",
       "1412       3617000             109.744146             109.964855   \n",
       "\n",
       "      avg_bid_non_us_at  ...  avg_bid_us_before  avg_ask_us_before  \\\n",
       "0            120.078801  ...         120.053826         120.296176   \n",
       "1            119.941938  ...         119.317563         119.559440   \n",
       "2            119.354526  ...         119.155725         119.395276   \n",
       "3            119.023857  ...         118.944936         119.184065   \n",
       "4            118.923957  ...         119.011869         119.252133   \n",
       "...                 ...  ...                ...                ...   \n",
       "1408         110.634255  ...         110.518371         110.740630   \n",
       "1409         110.561328  ...         110.322567         110.544434   \n",
       "1410         110.086803  ...         109.666224         109.886777   \n",
       "1411         109.680210  ...         109.671219         109.891782   \n",
       "1412         109.759131  ...         109.007883         109.227118   \n",
       "\n",
       "      avg_bid_us_at  avg_ask_us_at  stock_num_per_unit  adr_num_per_unit  \\\n",
       "0        120.048831     120.291171                 2.0                 1   \n",
       "1        119.319561     119.560441                 2.0                 1   \n",
       "2        119.140740     119.381262                 2.0                 1   \n",
       "3        118.949931     119.190071                 2.0                 1   \n",
       "4        119.006874     119.247128                 2.0                 1   \n",
       "...             ...            ...                 ...               ...   \n",
       "1408     110.515374     110.737627                 2.0                 1   \n",
       "1409     110.314575     110.537427                 2.0                 1   \n",
       "1410     109.680210     109.900791                 2.0                 1   \n",
       "1411     109.676214     109.896787                 2.0                 1   \n",
       "1412     109.011879     109.231122                 2.0                 1   \n",
       "\n",
       "      stock_open_per_unit  stock_close_per_unit  adr_open_per_unit  \\\n",
       "0                 16652.0               16496.0             137.67   \n",
       "1                 16432.0               16570.0             138.69   \n",
       "2                 16500.0               16546.0             139.23   \n",
       "3                 16570.0               16618.0             139.05   \n",
       "4                 16618.0               16594.0             138.99   \n",
       "...                   ...                   ...                ...   \n",
       "1408              17388.0               16846.0             153.60   \n",
       "1409              16990.0               16922.0             154.16   \n",
       "1410              17140.0               16732.0             153.10   \n",
       "1411              16948.0               16974.0             154.84   \n",
       "1412              16996.0               16836.0             154.35   \n",
       "\n",
       "      adr_close_per_unit  \n",
       "0                 137.56  \n",
       "1                 138.66  \n",
       "2                 139.08  \n",
       "3                 138.98  \n",
       "4                 138.43  \n",
       "...                  ...  \n",
       "1408              154.16  \n",
       "1409              155.38  \n",
       "1410              153.65  \n",
       "1411              154.70  \n",
       "1412              153.38  \n",
       "\n",
       "[1413 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variant 1 - Begin each trade on Asian market open (Evaluate after US market closes)\n",
    "\n",
    "To open a position, we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock of the same row. We buy the stock on the next trading OPEN for Asian/US market\n",
    "\n",
    "To close a position,  we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock of the same row. We sell the stock on the next trading next OPEN for Asian/US market\n",
    "\n",
    "For each row:\n",
    "    stock_open, stock_close, adr_open, adr_close\n",
    "    After these 4 events, assess condition (right before the Asian market opens ~ 6.59PM EST)\n",
    "    Place trade on next row (First trade stock on Asian market open, then trade ADR on US market open)\n",
    "    \n",
    "start_date: First date (EST) we may place a trade\n",
    "end_date: Last date (EST) we may place a trade\n",
    "portfolio_values: Stores value of portfolio at each date from one day before the start_date, to the end_date (inclusive), when Asian market opens (EST ~ 7:00 PM)\n",
    "\"\"\"\n",
    "def pairs_trade_v1(merged_df, lookback = 100, cash = 100000, entry = 1, exit = 0, stop_loss = 3, \n",
    "                   start_date = \"2016-01-01\", end_date = \"2021-01-31\", slippage_bps = 10, \n",
    "                   borrowing_bps = 50, risk_lookback = 100, var_ci = 0.95, var_limit = 0.1, max_drawdown_limit = 0.2, \n",
    "                   sigma_limit = 0.05, maximum_holding_period = 30, volume_lookback = 5):\n",
    "    \n",
    "    # Accounts for slippage and transaction costs\n",
    "    short_multiplier = 1 - 0.0001*slippage_bps\n",
    "    long_multiplier = 1 + 0.0001*slippage_bps\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    # For book-keeping, since we shall store the portfolio value of the day before\n",
    "    prev_cash, prev_adr_pos = cash, adr_pos\n",
    "    holding_period = None\n",
    "    diff_record_bid = deque(maxlen = lookback)\n",
    "    diff_record_ask = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "    portfolio_values = []\n",
    "    dates = []\n",
    "    hits = []\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "\n",
    "        if index+1 < len(merged_df) and index > 0:\n",
    "            \n",
    "            # Add portfolio value for the day before\n",
    "            prev_date = merged_df.loc[index - 1, \"date\"]\n",
    "            if row[\"date\"] >= start_date and prev_date <= end_date:\n",
    "                dates.append(prev_date)\n",
    "                portfolio_values.append(prev_cash + prev_adr_pos*merged_df.loc[index - 1, 'adr_close'] \n",
    "                                        + stock_pos*(row['stock_open']/row['avg_ask_non_us_at']))\n",
    "\n",
    "            diff_record_bid.append(row['adr_close_per_unit'] \n",
    "                                   - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before'])\n",
    "            diff_record_ask.append(row['adr_close_per_unit'] \n",
    "                                   - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_ask_non_us_before'])\n",
    "\n",
    "            # We place one trade the day itself (Asian), one trade the day after (US)\n",
    "            if len(diff_record_bid) < lookback or row[\"date\"] < start_date or merged_df.loc[index+1, \"date\"] > end_date:\n",
    "                continue\n",
    "            \n",
    "            # Update cash/adr position after portfolio values has been updated\n",
    "            if stock_pos > 0:\n",
    "                holding_period += 1\n",
    "                cash -= 0.0001*borrowing_bps*(1/252)*abs(adr_pos)*merged_df.loc[index - 1, 'adr_close']\n",
    "            prev_cash, prev_adr_pos = cash, adr_pos\n",
    "\n",
    "            ask_mean = np.array(diff_record_ask).mean()\n",
    "            bid_std = np.array(diff_record_bid).std()\n",
    "            ask_std = np.array(diff_record_ask).std()\n",
    "            \n",
    "            # If we have passed the initial lookback window and are in the specified dates\n",
    "            # enter the position if diff is significant\n",
    "            if diff_record_bid[-1] > ask_mean + entry*bid_std and diff_record_bid[-1] <= ask_mean + stop_loss*bid_std:\n",
    "                if stock_pos == 0 and adr_pos == 0:\n",
    "                    portfolio_value_before_entering = cash\n",
    "                    adr_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"adr_volume\"].mean()/row[\"adr_num_per_unit\"])\n",
    "                    stock_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"stock_volume\"].mean()/row[\"stock_num_per_unit\"])\n",
    "                    units = int(min((0.5*cash)/row['adr_close_per_unit'],\n",
    "                                    (0.5*cash)/(row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before']), \n",
    "                                    adr_volume, \n",
    "                                    stock_volume))\n",
    "                    adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                    stock_quantity = int(units*row[\"stock_num_per_unit\"])\n",
    "                    \n",
    "                    # Take portfolio value for each previous day when the Asian market opens\n",
    "                    temp_risk_lookback = min(risk_lookback, index)\n",
    "                    stock_temp = merged_df.loc[(index - temp_risk_lookback + 1):index].copy()\n",
    "                    stock_values = np.array((stock_temp[\"stock_open\"]/stock_temp[\"avg_ask_non_us_at\"])*stock_quantity) \n",
    "                    adr_values = np.array(merged_df.loc[(index - temp_risk_lookback):(index-1)][\"adr_close\"]*adr_quantity)\n",
    "                    sigma, var, max_drawdown_abs = get_risk_statistics(stock_values, adr_values, var_ci)\n",
    "                    if (var > portfolio_value_before_entering*var_limit or \n",
    "                        max_drawdown_abs > max_drawdown_limit*starting_cash or \n",
    "                        sigma > portfolio_value_before_entering*sigma_limit):\n",
    "                        frac = min((portfolio_value_before_entering*var_limit)/var, \n",
    "                                   (max_drawdown_limit*starting_cash)/max_drawdown_abs,\n",
    "                                  (portfolio_value_before_entering*sigma_limit)/sigma)\n",
    "                        units = int(frac*units)\n",
    "                        if units == 0:\n",
    "                            continue\n",
    "                        adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                        stock_quantity = int(units*row[\"stock_num_per_unit\"])                        \n",
    "                    \n",
    "                    stock_pos += stock_quantity\n",
    "                    stock_px_fx = merged_df.loc[index+1,'stock_open']*long_multiplier\n",
    "                    stock_px = stock_px_fx/merged_df.loc[index+1,'avg_bid_non_us_at']\n",
    "                    cash -= stock_px*stock_quantity\n",
    "                    # We store the current cash/adr position, because the trade below will occur on the next day (EST)\n",
    "                    prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                    \n",
    "                    adr_pos -= adr_quantity\n",
    "                    adr_px = merged_df.loc[index+1,'adr_open']*short_multiplier\n",
    "                    cash += adr_quantity*adr_px\n",
    "                    \n",
    "                    holding_period = 0\n",
    "                    trade_records.append(\"Opening positions:\\n\")\n",
    "                    # Times in EST\n",
    "                    trade_records.append(f\"We bought {stock_quantity} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We sold {adr_quantity} shares of ADR at the price of {adr_px} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "\n",
    "            # Liquidation condition\n",
    "            elif (diff_record_ask[-1] < ask_mean + exit*ask_std or \n",
    "                  diff_record_bid[-1] > ask_mean + stop_loss*bid_std or \n",
    "                  holding_period == maximum_holding_period):\n",
    "                if stock_pos > 0 and adr_pos < 0 : \n",
    "                    stock_px_fx = merged_df.loc[index+1,'stock_open']*short_multiplier\n",
    "                    stock_px = stock_px_fx/merged_df.loc[index+1,'avg_ask_non_us_at']\n",
    "                    cash += stock_pos*stock_px\n",
    "                    # We store the current cash/adr position, because the trade below will occur on the next day (EST)\n",
    "                    prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                    \n",
    "                    adr_px = merged_df.loc[index+1,'adr_open']*long_multiplier\n",
    "                    cash -= abs(adr_pos)*adr_px\n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    # Times in EST\n",
    "                    trade_records.append(f\"We sold {stock_pos} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We bought {-adr_pos} shares of ADR at the price of {adr_px} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "                    holding_period = None\n",
    "                    if cash > portfolio_value_before_entering:\n",
    "                        hits.append(1)\n",
    "                    else:\n",
    "                        hits.append(0)\n",
    "\n",
    "    ret = (portfolio_values[-1] - starting_cash)/starting_cash\n",
    "    \n",
    "    return ret, trade_records, portfolio_values, hits, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_and_store_statistics(pairs_trade_strategy, filename):\n",
    "    for (country, adr) in list_pairs:\n",
    "        merged_df = data_processing(country, adr, fx_dict)\n",
    "        ret, trade_records, portfolio_values, hits, dates = pairs_trade_strategy(merged_df)\n",
    "        ret = np.round(ret*100, 2)\n",
    "        hit_ratio = None\n",
    "        logs = [f'The return of ADR_underlying pairs trading for {adr} from {country} is {0.00}%, no trades were placed.\\n']\n",
    "        if hits:\n",
    "            hit_ratio = np.round(np.mean(hits)*100,2)\n",
    "            max_drawdown = np.round(calc_max_drawdown(portfolio_values)*100,2)\n",
    "            logs = [f'The return of ADR_underlying pairs trading for {adr} from {country} is {ret}%\\nThe hit ratio is {hit_ratio}%\\nThe max drawdown is {max_drawdown}%\\n']\n",
    "            print(\"Country: {}, ADR_Stock: {}, Return: {}%, Hit Ratio: {}%, Max Drawdown: {}%\".format(country, adr, ret, hit_ratio, max_drawdown))\n",
    "        else:\n",
    "            print(\"Country: {}, ADR_Stock: {}, Return: {}%, Hit Ratio: None, Max Drawdown: 0.00%\".format(country, adr, ret))\n",
    "        logs = logs + trade_records \n",
    "        fname = f'eric_jh_data/{country}/{adr}/' + filename\n",
    "        f = open(fname, 'w')\n",
    "        f.writelines(logs)\n",
    "        f.close()\n",
    "    return dates, portfolio_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_returns(date, cash, country, adr, num_xticks = 15, save = False):\n",
    "    fig = plt.figure(figsize = (20, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(date, cash)\n",
    "    plt.xticks(np.arange(0, len(date), (len(date) - 1 )// num_xticks), rotation = 30, ha = 'right', fontsize = 14)\n",
    "    plt.xlim(0, len(date))\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.grid(True)\n",
    "    plt.title(f'PnL Chart for {adr} pair from {country}', fontsize = 18)\n",
    "    if save:\n",
    "        fig.savefig(f'eric_jh_data/{country}/{adr}/pnl_plot.png')\n",
    "    else:\n",
    "        plt.show();\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variant 2 - Begin each trade on US market open (Evaluate after Asian market closes)\n",
    "\n",
    "To open a position, we check the CLOSE price of adr of the previous row, compared to CLOSE px of \n",
    "stock of the current row. We buy the stock on the next trading OPEN for Asian/US market\n",
    "\n",
    "To close a position, we check the CLOSE price of adr of the previous row, compared to CLOSE px of \n",
    "stock of the current row. We sell the stock on the next trading next OPEN for Asian/US market\n",
    "\n",
    "For each row:\n",
    "    stock_open, stock_close, (assess), adr_open, adr_close\n",
    "    After first 2 events events, assess condition (right before the US market opens ~ 9.29AM EST)\n",
    "    Place trade on current and next row (First trade ADR on US market open, then trade stock on Asian market open)\n",
    "    \n",
    "start_date: First date (EST) we may place a trade\n",
    "end_date: Last date (EST) we may place a trade\n",
    "portfolio_values: Stores value of portfolio at each date from one day before the start_date, to the end_date, when the Asian market opens\n",
    "\"\"\"\n",
    "def pairs_trade_v2(merged_df, lookback = 100, cash = 100000, entry = 1, exit = 0, stop_loss = 3, \n",
    "                   start_date = \"2016-01-01\", end_date = \"2021-01-31\", slippage_bps = 10, \n",
    "                   borrowing_bps = 50, risk_lookback = 100, var_ci = 0.95, var_limit = 0.1, max_drawdown_limit = 0.2, \n",
    "                   sigma_limit = 0.05, maximum_holding_period = 30, volume_lookback = 5):\n",
    "    \n",
    "    # Accounts for slippage and transaction costs\n",
    "    short_multiplier = 1 - 0.0001*slippage_bps\n",
    "    long_multiplier = 1 + 0.0001*slippage_bps\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    holding_period = None\n",
    "    # For book-keeping, since we shall store the portfolio value of the day before\n",
    "    diff_record_bid = deque(maxlen = lookback)\n",
    "    diff_record_ask = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "    portfolio_values = []\n",
    "    dates = []\n",
    "    hits = []\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "        \n",
    "        if index+1 < len(merged_df) and index > 0:\n",
    "            \n",
    "            # Add portfolio value for the day before\n",
    "            prev_date = merged_df.loc[index - 1, \"date\"]\n",
    "            if row[\"date\"] >= start_date and prev_date <= end_date:\n",
    "                dates.append(prev_date)\n",
    "                portfolio_values.append(cash + adr_pos*merged_df.loc[index - 1, 'adr_close'] + stock_pos*(row['stock_open']/row['avg_ask_non_us_at']))\n",
    "\n",
    "            diff_record_bid.append(merged_df.loc[index-1,'adr_close_per_unit'] - row['stock_close_per_unit']/row['avg_bid_us_before'])\n",
    "            diff_record_ask.append(merged_df.loc[index-1,'adr_close_per_unit'] - row['stock_close_per_unit']/row['avg_ask_us_before'])\n",
    "\n",
    "            # We place both trades the day itself\n",
    "            if len(diff_record_bid) < lookback or row[\"date\"] < start_date or row[\"date\"] > end_date:\n",
    "                continue\n",
    "\n",
    "            if stock_pos > 0:\n",
    "                holding_period += 1\n",
    "                cash -= 0.0001*borrowing_bps*(1/252)*abs(adr_pos)*merged_df.loc[index - 1, 'adr_close']\n",
    "                \n",
    "            ask_mean = np.array(diff_record_ask).mean()\n",
    "            bid_std = np.array(diff_record_bid).std()\n",
    "            ask_std = np.array(diff_record_ask).std()\n",
    "            \n",
    "            # If we have passed the initial lookback window and are in the specified dates\n",
    "            # enter the position if diff is significant\n",
    "            if diff_record_bid[-1] > ask_mean + entry*bid_std and diff_record_bid[-1] <= ask_mean + stop_loss*bid_std:\n",
    "                if stock_pos == 0 and adr_pos == 0:\n",
    "                    portfolio_value_before_entering = cash\n",
    "                    adr_volume = 0.2*(merged_df.loc[index-volume_lookback:index - 1,:][\"adr_volume\"].mean()/row[\"adr_num_per_unit\"])\n",
    "                    stock_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"stock_volume\"].mean()/row[\"stock_num_per_unit\"])\n",
    "                    units = int(min((0.5*cash)/merged_df.loc[index-1,'adr_close_per_unit'],\n",
    "                                    (0.5*cash)/(row['stock_close_per_unit']/row['avg_bid_us_before']), \n",
    "                                    adr_volume, \n",
    "                                    stock_volume))\n",
    "                    adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                    stock_quantity = int(units*row[\"stock_num_per_unit\"])\n",
    "                    # Take portfolio value for each previous day when the Asian market opens\n",
    "                    temp_risk_lookback = min(risk_lookback, index)\n",
    "                    stock_temp = merged_df.loc[(index - temp_risk_lookback + 1):index].copy()\n",
    "                    stock_values = np.array((stock_temp[\"stock_open\"]/stock_temp[\"avg_ask_non_us_at\"])*stock_quantity) \n",
    "                    adr_values = np.array(merged_df.loc[(index - temp_risk_lookback):(index-1)][\"adr_close\"]*adr_quantity)\n",
    "                    sigma, var, max_drawdown_abs = get_risk_statistics(stock_values, adr_values, var_ci)\n",
    "                    if (var > portfolio_value_before_entering*var_limit or \n",
    "                        max_drawdown_abs > max_drawdown_limit*starting_cash or \n",
    "                        sigma > portfolio_value_before_entering*sigma_limit):\n",
    "                        frac = min((portfolio_value_before_entering*var_limit)/var, \n",
    "                                   (max_drawdown_limit*starting_cash)/max_drawdown_abs,\n",
    "                                  (portfolio_value_before_entering*sigma_limit)/sigma)\n",
    "                        units = int(frac*units)\n",
    "                        if units == 0:\n",
    "                            continue\n",
    "                        adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                        stock_quantity = int(units*row[\"stock_num_per_unit\"])  \n",
    "                    \n",
    "                    adr_pos -= adr_quantity\n",
    "                    adr_px = row['adr_open']*short_multiplier\n",
    "                    cash += adr_quantity*adr_px\n",
    "                    \n",
    "                    stock_pos += stock_quantity\n",
    "                    stock_px_fx = merged_df.loc[index+1,'stock_open']*long_multiplier\n",
    "                    stock_px = stock_px_fx/merged_df.loc[index+1,'avg_bid_non_us_at']\n",
    "                    cash -= stock_px*stock_quantity\n",
    "                    \n",
    "                    holding_period = 0\n",
    "                    trade_records.append(\"Opening positions:\\n\")\n",
    "                    # Times in EST\n",
    "                    trade_records.append(f\"We sold {adr_quantity} shares of ADR at the price of {adr_px} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We bought {stock_quantity} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "\n",
    "            # Liquidation condition\n",
    "            elif (diff_record_ask[-1] < ask_mean + exit*ask_std or \n",
    "                  diff_record_bid[-1] > ask_mean + stop_loss*bid_std or \n",
    "                  holding_period == maximum_holding_period):\n",
    "                if stock_pos > 0 and adr_pos < 0 : \n",
    "                    adr_px = row['adr_open']*long_multiplier\n",
    "                    cash -= abs(adr_pos)*adr_px\n",
    "                    stock_px_fx = merged_df.loc[index+1,'stock_open']*short_multiplier\n",
    "                    stock_px = stock_px_fx/merged_df.loc[index+1,'avg_ask_non_us_at']\n",
    "                    cash += stock_pos*stock_px\n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    # Times in EST\n",
    "                    trade_records.append(f\"We bought {-adr_pos} shares of ADR at the price of {adr_px} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We sold {stock_pos} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "                    holding_period = None\n",
    "                    if cash > portfolio_value_before_entering:\n",
    "                        hits.append(1)\n",
    "                    else:\n",
    "                        hits.append(0)\n",
    "\n",
    "    ret = (portfolio_values[-1] - starting_cash)/starting_cash\n",
    "    \n",
    "    return ret, trade_records, portfolio_values, hits, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variant 3a \n",
    "- Begin each trade on either US market open or Asian market open\n",
    "- Regressions are done for the similar \"type\" of trade\n",
    "    i.e. if we are entering at a certain time, we do a regression based on the values obtained at the same time each day\n",
    "\n",
    "For each row:\n",
    "    stock_open, stock_close, (assess condition 1), adr_open, adr_close, (assess condition 2)\n",
    "    If not condition 2 - No action taken: \n",
    "        After first 2 events, Assess condition 1 (right before the US market opens ~ 9.29AM EST)\n",
    "        If condition 1:\n",
    "            Place trade on current and next row (First trade ADR on US market open, then trade stock on Asian market open)\n",
    "    If not condition 1 - No action taken:\n",
    "        After next 2 events occur, assess condition 2\n",
    "        If condition 2:\n",
    "            Place trade on next row (First trade ADR on Asian market open, then trade stock on US market open)\n",
    "    \n",
    "start_date: First date (EST) we may place a trade\n",
    "end_date: Last date (EST) we may place a trade\n",
    "portfolio_values: Stores value of portfolio at each date from one day before the start_date, to the end_date, when the Asian market opens\n",
    "\"\"\"\n",
    "def pairs_trade_v3a(merged_df, lookback = 100, cash = 100000, entry_cond1_val = 1, entry_cond2_val = 1, \n",
    "                    exit_cond1_val = 0, exit_cond2_val = 0, stop_loss_cond1 = 3, stop_loss_cond2 = 3, \n",
    "                    start_date = \"2016-01-01\", end_date = \"2021-01-31\", slippage_bps = 10, \n",
    "                    borrowing_bps = 50, risk_lookback = 100, var_ci = 0.95, var_limit = 0.1, max_drawdown_limit = 0.2, \n",
    "                    sigma_limit = 0.05, maximum_holding_period = 30, volume_lookback = 5):\n",
    "\n",
    "    # Accounts for slippage and transaction costs\n",
    "    short_multiplier = 1 - 0.0001*slippage_bps\n",
    "    long_multiplier = 1 + 0.0001*slippage_bps\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    holding_period = None\n",
    "    trade_type = None\n",
    "    # For book-keeping, since we shall store the portfolio value of the day before\n",
    "    prev_cash, prev_adr_pos = cash, adr_pos\n",
    "    diff_record_bid_cond1 = deque(maxlen = lookback)\n",
    "    diff_record_ask_cond1 = deque(maxlen = lookback)\n",
    "    diff_record_bid_cond2 = deque(maxlen = lookback)\n",
    "    diff_record_ask_cond2 = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "    portfolio_values = []\n",
    "    dates = []\n",
    "    hits = []\n",
    "    enter_cond1, exit_cond1, enter_cond2, exit_cond2 = False, False, False, False\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "                    \n",
    "        if index+1 < len(merged_df) and index > 0:\n",
    "            \n",
    "            # Add portfolio value for the day before\n",
    "            prev_date = merged_df.loc[index - 1, \"date\"]\n",
    "            if row[\"date\"] >= start_date and prev_date <= end_date:\n",
    "                dates.append(prev_date)\n",
    "                portfolio_values.append(prev_cash + prev_adr_pos*merged_df.loc[index - 1, 'adr_close'] + stock_pos*(row['stock_open']/row['avg_ask_non_us_at']))\n",
    "            \n",
    "            # Before US Market Opens\n",
    "            diff_record_bid_cond1.append(merged_df.loc[index-1,'adr_close_per_unit'] - row['stock_close_per_unit']/row['avg_bid_us_before'])\n",
    "            diff_record_ask_cond1.append(merged_df.loc[index-1,'adr_close_per_unit'] - row['stock_close_per_unit']/row['avg_ask_us_before'])\n",
    "            # Before Asian Market Opens\n",
    "            diff_record_bid_cond2.append(row['adr_close_per_unit'] - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before'])\n",
    "            diff_record_ask_cond2.append(row['adr_close_per_unit'] - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_ask_non_us_before'])\n",
    "\n",
    "\n",
    "            # row[\"date\"] is between start_date (inclusive) and end_date (inclusive)\n",
    "            if len(diff_record_bid_cond1) < lookback or row[\"date\"] < start_date or row[\"date\"] > end_date:\n",
    "                continue\n",
    "\n",
    "            # Update cash/adr position after portfolio values has been updated\n",
    "            if stock_pos > 0:\n",
    "                holding_period += 1\n",
    "                cash -= 0.0001*borrowing_bps*(1/252)*abs(adr_pos)*merged_df.loc[index - 1, 'adr_close']\n",
    "            prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                \n",
    "            ask_mean_cond1 = np.array(diff_record_ask_cond1).mean()\n",
    "            bid_std_cond1 = np.array(diff_record_bid_cond1).std()\n",
    "            ask_std_cond1 = np.array(diff_record_ask_cond1).std()\n",
    "            ask_mean_cond2 = np.array(diff_record_ask_cond2).mean()\n",
    "            bid_std_cond2 = np.array(diff_record_bid_cond2).std()\n",
    "            ask_std_cond2 = np.array(diff_record_ask_cond2).std()\n",
    "            \n",
    "            # If a concurrent trade is not already being placed\n",
    "            if not (enter_cond2 or exit_cond2):\n",
    "                enter_cond1 = (diff_record_bid_cond1[-1] > ask_mean_cond1 + entry_cond1_val*bid_std_cond1 \n",
    "                               and diff_record_bid_cond1[-1] <= ask_mean_cond1 + stop_loss_cond1*bid_std_cond1\n",
    "                               and stock_pos == 0 and adr_pos == 0)\n",
    "                exit_cond1 = ((diff_record_ask_cond1[-1] < ask_mean_cond1 + exit_cond1_val*ask_std_cond1 \n",
    "                              or diff_record_bid_cond1[-1] > ask_mean_cond1 + stop_loss_cond1*bid_std_cond1\n",
    "                              or (holding_period == maximum_holding_period and trade_type == 1))\n",
    "                              and stock_pos > 0 and adr_pos < 0)\n",
    "                    \n",
    "                if enter_cond1:\n",
    "                    portfolio_value_before_entering = cash\n",
    "                    adr_volume = 0.2*(merged_df.loc[index-volume_lookback:index - 1,:][\"adr_volume\"].mean()/row[\"adr_num_per_unit\"])\n",
    "                    stock_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"stock_volume\"].mean()/row[\"stock_num_per_unit\"])\n",
    "                    units = int(min((0.5*cash)/row['adr_close_per_unit'],\n",
    "                                    (0.5*cash)/(row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before']), \n",
    "                                    adr_volume, \n",
    "                                    stock_volume))\n",
    "                    adr_quantity = int(units*row[\"adr_num_per_unit\"])*short_multiplier\n",
    "                    stock_quantity = int(units*row[\"stock_num_per_unit\"])\n",
    "                    \n",
    "                    # Take portfolio value for each previous day when the Asian market opens\n",
    "                    temp_risk_lookback = min(risk_lookback, index)\n",
    "                    stock_temp = merged_df.loc[(index - temp_risk_lookback + 1):index].copy()\n",
    "                    stock_values = np.array((stock_temp[\"stock_open\"]/stock_temp[\"avg_ask_non_us_at\"])*stock_quantity) \n",
    "                    adr_values = np.array(merged_df.loc[(index - temp_risk_lookback):(index-1)][\"adr_close\"]*adr_quantity)\n",
    "                    sigma, var, max_drawdown_abs = get_risk_statistics(stock_values, adr_values, var_ci)\n",
    "                    if (var > portfolio_value_before_entering*var_limit or \n",
    "                        max_drawdown_abs > max_drawdown_limit*starting_cash or \n",
    "                        sigma > portfolio_value_before_entering*sigma_limit):\n",
    "                        frac = min((portfolio_value_before_entering*var_limit)/var, \n",
    "                                   (max_drawdown_limit*starting_cash)/max_drawdown_abs,\n",
    "                                  (portfolio_value_before_entering*sigma_limit)/sigma)\n",
    "                        units = int(frac*units)\n",
    "                        if units == 0:\n",
    "                            enter_cond1 = False\n",
    "                        adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                        stock_quantity = int(units*row[\"stock_num_per_unit\"])\n",
    "                    if units != 0:\n",
    "                        adr_pos -= adr_quantity\n",
    "                        adr_px = row['adr_open']\n",
    "                        cash += adr_quantity*adr_px\n",
    "\n",
    "                        stock_pos += stock_quantity\n",
    "                        stock_px_fx = merged_df.loc[index+1,'stock_open']*long_multiplier\n",
    "                        stock_px = stock_px_fx/merged_df.loc[index+1,'avg_bid_non_us_at']\n",
    "                        cash -= stock_px*stock_quantity\n",
    "                        prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                        holding_period = 0\n",
    "                        trade_type = 1\n",
    "                        \n",
    "                        trade_records.append(\"Opening positions:\\n\")\n",
    "                        # Times in EST\n",
    "                        trade_records.append(f\"We sold {adr_quantity} shares of ADR at the price of {adr_px} on {row['date']}\\n\")\n",
    "                        trade_records.append(f\"We bought {stock_quantity} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "\n",
    "                elif exit_cond1:\n",
    "                    \n",
    "                    adr_px = row['adr_open']*long_multiplier\n",
    "                    cash -= abs(adr_pos)*adr_px\n",
    "                    stock_px_fx = merged_df.loc[index+1,'stock_open']*short_multiplier\n",
    "                    stock_px = stock_px_fx/merged_df.loc[index+1,'avg_ask_non_us_at']\n",
    "                    cash += stock_pos*stock_px\n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    # Times in EST\n",
    "                    trade_records.append(f\"We bought {-adr_pos} shares of ADR at the price of {adr_px} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We sold {stock_pos} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "                    holding_period = None\n",
    "                    trade_type = None\n",
    "                    prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                    if cash > portfolio_value_before_entering:\n",
    "                        hits.append(1)\n",
    "                    else:\n",
    "                        hits.append(0)\n",
    "                    \n",
    "            # If a concurrent trade is not already being placed\n",
    "            # The 2nd trade of condition 2 falls on the next day\n",
    "            if not (enter_cond1 or exit_cond1) and merged_df.loc[index+1, \"date\"] <= end_date:\n",
    "                # Check and possibly trade condition 2\n",
    "                enter_cond2 = (diff_record_bid_cond2[-1] > ask_mean_cond2 + entry_cond2_val*bid_std_cond2 \n",
    "                               and diff_record_bid_cond2[-1] <= ask_mean_cond2 + stop_loss_cond2*bid_std_cond2\n",
    "                               and stock_pos == 0 and adr_pos == 0)\n",
    "                exit_cond2 = ((diff_record_ask_cond2[-1] < ask_mean_cond2 + exit_cond2_val*ask_std_cond2 \n",
    "                              or diff_record_bid_cond2[-1] > ask_mean_cond2 + stop_loss_cond2*bid_std_cond2\n",
    "                              or (holding_period == maximum_holding_period and trade_type == 2))\n",
    "                              and stock_pos > 0 and adr_pos < 0)\n",
    "                    \n",
    "                if enter_cond2:\n",
    "                    portfolio_value_before_entering = cash\n",
    "                    adr_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"adr_volume\"].mean()/row[\"adr_num_per_unit\"])\n",
    "                    stock_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"stock_volume\"].mean()/row[\"stock_num_per_unit\"])\n",
    "                    units = int(min((0.5*cash)/merged_df.loc[index-1,'adr_close_per_unit'],\n",
    "                                    (0.5*cash)/(row['stock_close_per_unit']/row['avg_bid_us_before']), \n",
    "                                    adr_volume, \n",
    "                                    stock_volume))\n",
    "                    adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                    stock_quantity = int(units*row[\"stock_num_per_unit\"])\n",
    "                    \n",
    "                    # Take portfolio value for each previous day when the Asian market opens\n",
    "                    temp_risk_lookback = min(risk_lookback, index)\n",
    "                    stock_temp = merged_df.loc[(index - temp_risk_lookback + 1):index].copy()\n",
    "                    stock_values = np.array((stock_temp[\"stock_open\"]/stock_temp[\"avg_ask_non_us_at\"])*stock_quantity) \n",
    "                    adr_values = np.array(merged_df.loc[(index - temp_risk_lookback):(index-1)][\"adr_close\"]*adr_quantity)\n",
    "                    sigma, var, max_drawdown_abs = get_risk_statistics(stock_values, adr_values, var_ci)\n",
    "                    if (var > portfolio_value_before_entering*var_limit or \n",
    "                        max_drawdown_abs > max_drawdown_limit*starting_cash or \n",
    "                        sigma > portfolio_value_before_entering*sigma_limit):\n",
    "                        frac = min((portfolio_value_before_entering*var_limit)/var, \n",
    "                                   (max_drawdown_limit*starting_cash)/max_drawdown_abs,\n",
    "                                  (portfolio_value_before_entering*sigma_limit)/sigma)\n",
    "                        units = int(frac*units)\n",
    "                        if units == 0:\n",
    "                            enter_cond2 = False\n",
    "                        adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                        stock_quantity = int(units*row[\"stock_num_per_unit\"]) \n",
    "                    if units != 0:\n",
    "                        stock_pos += stock_quantity\n",
    "                        stock_px_fx = merged_df.loc[index+1,'stock_open']*long_multiplier\n",
    "                        stock_px = stock_px_fx/merged_df.loc[index+1,'avg_bid_non_us_at']\n",
    "                        cash -= stock_px*stock_quantity\n",
    "                        # We store the current cash/adr position, because the trade below will occur on the next day (EST)\n",
    "                        prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                        \n",
    "                        adr_pos -= adr_quantity\n",
    "                        adr_px = merged_df.loc[index+1,'adr_open']*short_multiplier\n",
    "                        cash += adr_quantity*adr_px\n",
    "                        \n",
    "                        holding_period = 0\n",
    "                        trade_type = 2\n",
    "                        trade_records.append(\"Opening positions:\\n\")\n",
    "                        # Times in EST\n",
    "                        trade_records.append(f\"We bought {stock_quantity} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                        trade_records.append(f\"We sold {adr_quantity} shares of ADR at the price of {adr_px} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "\n",
    "                elif exit_cond2:\n",
    "                    stock_px_fx = merged_df.loc[index+1,'stock_open']\n",
    "                    stock_px = stock_px_fx/merged_df.loc[index+1,'avg_ask_non_us_at']*short_multiplier\n",
    "                    cash += stock_pos*stock_px\n",
    "                    # We store the current cash/adr position, because the trade below will occur on the next day (EST)\n",
    "                    prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                    \n",
    "                    adr_px = merged_df.loc[index+1,'adr_open']*long_multiplier\n",
    "                    cash -= abs(adr_pos)*adr_px\n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    # Times in EST\n",
    "                    trade_records.append(f\"We sold {stock_pos} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We bought {-adr_pos} shares of ADR at the price of {adr_px} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "                    holding_period = None\n",
    "                    trade_type = None\n",
    "                    if cash > portfolio_value_before_entering:\n",
    "                        hits.append(1)\n",
    "                    else:\n",
    "                        hits.append(0)\n",
    "\n",
    "    ret = (portfolio_values[-1] - starting_cash)/starting_cash\n",
    "\n",
    "    return ret, trade_records, portfolio_values, hits, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variant 3b\n",
    "- Begin each trade on either US market open or Asian market open\n",
    "- Regressions are done for all data collected in lookback window\n",
    "\n",
    "For each row:\n",
    "    stock_open, stock_close, (assess condition 1), adr_open, adr_close, (assess condition 2)\n",
    "    If not condition 2 - No action taken: \n",
    "        After first 2 events, Assess condition 1 (right before the US market opens ~ 9.29AM EST)\n",
    "        If condition 1:\n",
    "            Place trade on current and next row (First trade ADR on US market open, then trade stock on Asian market open)\n",
    "    If not condition 1 - No action taken:\n",
    "        After next 2 events occur, assess condition 2\n",
    "        If condition 2:\n",
    "            Place trade on next row (First trade ADR on Asian market open, then trade stock on US market open)\n",
    "    \n",
    "start_date: First date (EST) we may place a trade\n",
    "end_date: Last date (EST) we may place a trade\n",
    "portfolio_values: Stores value of portfolio at each date from one day before the start_date, to the end_date, when the Asian market opens\n",
    "\"\"\"\n",
    "def pairs_trade_v3b(merged_df, lookback = 100, cash = 100000, entry_cond1_val = 1, entry_cond2_val = 1, \n",
    "                    exit_cond1_val = 0, exit_cond2_val = 0, stop_loss_cond1 = 3, stop_loss_cond2 = 3, \n",
    "                    start_date = \"2016-01-01\", end_date = \"2021-01-31\", slippage_bps = 10, \n",
    "                    borrowing_bps = 50, risk_lookback = 100, var_ci = 0.95, var_limit = 0.1, max_drawdown_limit = 0.2,\n",
    "                    sigma_limit = 0.05, maximum_holding_period = 30, volume_lookback = 5):\n",
    "    \n",
    "    # Accounts for slippage and transaction costs\n",
    "    short_multiplier = 1 - 0.0001*slippage_bps\n",
    "    long_multiplier = 1 + 0.0001*slippage_bps\n",
    "    # We assume lookback is given in terms of days\n",
    "    lookback *= 2\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    holding_period = None\n",
    "    trade_type = None\n",
    "    # For book-keeping, since we shall store the portfolio value of the day before\n",
    "    prev_cash, prev_adr_pos = cash, adr_pos\n",
    "    diff_record_bid = deque(maxlen = lookback)\n",
    "    diff_record_ask = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "    portfolio_values = []\n",
    "    dates = []\n",
    "    hits = []\n",
    "    enter_cond1, exit_cond1, enter_cond2, exit_cond2 = False, False, False, False\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "\n",
    "        if index+1 < len(merged_df) and index > 0:\n",
    "            \n",
    "            # Add portfolio value for the day before\n",
    "            prev_date = merged_df.loc[index - 1, \"date\"]\n",
    "            if row[\"date\"] >= start_date and prev_date <= end_date:\n",
    "                dates.append(prev_date)\n",
    "                portfolio_values.append(prev_cash + prev_adr_pos*merged_df.loc[index - 1, 'adr_close'] + stock_pos*(row['stock_open']/row['avg_ask_non_us_at']))\n",
    "            \n",
    "            # Before US Market Opens\n",
    "            diff_record_bid.append(merged_df.loc[index-1,'adr_close_per_unit'] - row['stock_close_per_unit']/row['avg_bid_us_before'])\n",
    "            diff_record_ask.append(merged_df.loc[index-1,'adr_close_per_unit'] - row['stock_close_per_unit']/row['avg_ask_us_before'])\n",
    "            if len(diff_record_bid) == lookback and row[\"date\"] >= start_date and row[\"date\"] <= end_date:\n",
    "                if stock_pos > 0:\n",
    "                    holding_period += 1\n",
    "                    cash -= 0.0001*borrowing_bps*(1/252)*abs(adr_pos)*merged_df.loc[index - 1, 'adr_close']\n",
    "                prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                    \n",
    "                ask_mean = np.array(diff_record_ask).mean()\n",
    "                bid_std = np.array(diff_record_bid).std()\n",
    "                ask_std = np.array(diff_record_ask).std()\n",
    "                # If a concurrent trade is not already being placed\n",
    "                if not (enter_cond2 or exit_cond2):\n",
    "                    enter_cond1 = (diff_record_bid[-1] > ask_mean + entry_cond1_val*bid_std\n",
    "                                   and diff_record_bid[-1] <= ask_mean + stop_loss_cond1*bid_std\n",
    "                                   and stock_pos == 0 and adr_pos == 0)\n",
    "                    exit_cond1 = ((diff_record_ask[-1] < ask_mean + exit_cond1_val*ask_std\n",
    "                                  or diff_record_bid[-1] > ask_mean + stop_loss_cond1*bid_std\n",
    "                                  or (holding_period == maximum_holding_period and trade_type == 1))\n",
    "                                  and stock_pos > 0 and adr_pos < 0)\n",
    "                    \n",
    "                    if enter_cond1:\n",
    "                        portfolio_value_before_entering = cash\n",
    "                        adr_volume = 0.2*(merged_df.loc[index-volume_lookback:index - 1,:][\"adr_volume\"].mean()/row[\"adr_num_per_unit\"])\n",
    "                        stock_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"stock_volume\"].mean()/row[\"stock_num_per_unit\"])\n",
    "                        units = int(min((0.5*cash)/row['adr_close_per_unit'],\n",
    "                                        (0.5*cash)/(row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before']), \n",
    "                                        adr_volume, \n",
    "                                        stock_volume))\n",
    "                        adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                        stock_quantity = int(units*row[\"stock_num_per_unit\"])\n",
    "                        \n",
    "                        temp_risk_lookback = min(risk_lookback, index)\n",
    "                        stock_temp = merged_df.loc[(index - temp_risk_lookback + 1):index].copy()\n",
    "                        stock_values = np.array((stock_temp[\"stock_open\"]/stock_temp[\"avg_ask_non_us_at\"])*stock_quantity) \n",
    "                        adr_values = np.array(merged_df.loc[(index - temp_risk_lookback):(index-1)][\"adr_close\"]*adr_quantity)\n",
    "                        sigma, var, max_drawdown_abs = get_risk_statistics(stock_values, adr_values, var_ci)\n",
    "                        if (var > portfolio_value_before_entering*var_limit or \n",
    "                            max_drawdown_abs > max_drawdown_limit*starting_cash or \n",
    "                            sigma > portfolio_value_before_entering*sigma_limit):\n",
    "                            frac = min((portfolio_value_before_entering*var_limit)/var, \n",
    "                                       (max_drawdown_limit*starting_cash)/max_drawdown_abs,\n",
    "                                      (portfolio_value_before_entering*sigma_limit)/sigma)\n",
    "                            units = int(frac*units)\n",
    "                            if units == 0:\n",
    "                                enter_cond1 = False\n",
    "                            adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                            stock_quantity = int(units*row[\"stock_num_per_unit\"]) \n",
    "                        if units != 0:\n",
    "                            adr_pos -= adr_quantity\n",
    "                            adr_px = row['adr_open']*short_multiplier\n",
    "                            cash += adr_quantity*adr_px\n",
    "\n",
    "                            stock_pos += stock_quantity\n",
    "                            stock_px_fx = merged_df.loc[index+1,'stock_open']*long_multiplier\n",
    "                            stock_px = stock_px_fx/merged_df.loc[index+1,'avg_bid_non_us_at']\n",
    "                            cash -= stock_px*stock_quantity\n",
    "                            prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                            holding_period = 0\n",
    "                            trade_type = 1\n",
    "                            trade_records.append(\"Opening positions:\\n\")\n",
    "                            # Times in EST\n",
    "                            trade_records.append(f\"We sold {adr_quantity} shares of ADR at the price of {adr_px} on {row['date']}\\n\")\n",
    "                            trade_records.append(f\"We bought {stock_quantity} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "\n",
    "                    elif exit_cond1:\n",
    "\n",
    "                        adr_px = row['adr_open']*long_multiplier\n",
    "                        cash -= abs(adr_pos)*adr_px\n",
    "                        stock_px_fx = merged_df.loc[index+1,'stock_open']*short_multiplier\n",
    "                        stock_px = stock_px_fx/merged_df.loc[index+1,'avg_ask_non_us_at']\n",
    "                        cash += stock_pos*stock_px\n",
    "                        trade_records.append(\"Closing positions:\\n\")\n",
    "                        # Times in EST\n",
    "                        trade_records.append(f\"We bought {-adr_pos} shares of ADR at the price of {adr_px} on {row['date']}\\n\")\n",
    "                        trade_records.append(f\"We sold {stock_pos} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                        stock_pos, adr_pos = 0, 0\n",
    "                        holding_period = None\n",
    "                        trade_type = None\n",
    "                        prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                        if cash > portfolio_value_before_entering:\n",
    "                            hits.append(1)\n",
    "                        else:\n",
    "                            hits.append(0)\n",
    "                        \n",
    "            # Before Asian Market Opens\n",
    "            diff_record_bid.append(row['adr_close_per_unit'] - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_bid_non_us_before'])\n",
    "            diff_record_ask.append(row['adr_close_per_unit'] - row['stock_close_per_unit']/merged_df.loc[index+1,'avg_ask_non_us_before'])\n",
    "            # The 2nd trade of condition 2 falls on the next day\n",
    "            if len(diff_record_bid) == lookback and row[\"date\"] >= start_date and merged_df.loc[index+1,\"date\"] <= end_date:\n",
    "                ask_mean = np.array(diff_record_ask).mean()\n",
    "                bid_std = np.array(diff_record_bid).std()\n",
    "                ask_std = np.array(diff_record_ask).std()\n",
    "                # If a concurrent trade is not already being placed\n",
    "                if not (enter_cond1 or exit_cond1):\n",
    "                    enter_cond2 = (diff_record_bid[-1] > ask_mean + entry_cond2_val*bid_std\n",
    "                                   and diff_record_bid[-1] <= ask_mean + stop_loss_cond2*bid_std\n",
    "                                   and stock_pos == 0 and adr_pos == 0)\n",
    "                    exit_cond2 = ((diff_record_ask[-1] < ask_mean + exit_cond2_val*ask_std\n",
    "                                  or diff_record_bid[-1] > ask_mean + stop_loss_cond2*bid_std\n",
    "                                  or (holding_period == maximum_holding_period and trade_type == 2))\n",
    "                                  and stock_pos > 0 and adr_pos < 0)\n",
    "\n",
    "                    if enter_cond2:\n",
    "                        portfolio_value_before_entering = cash\n",
    "                        adr_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"adr_volume\"].mean()/row[\"adr_num_per_unit\"])\n",
    "                        stock_volume = 0.2*(merged_df.loc[index-volume_lookback+1:index,:][\"stock_volume\"].mean()/row[\"stock_num_per_unit\"])\n",
    "                        units = int(min((0.5*cash)/merged_df.loc[index-1,'adr_close_per_unit'],\n",
    "                                        (0.5*cash)/(row['stock_close_per_unit']/row['avg_bid_us_before']), \n",
    "                                        adr_volume, \n",
    "                                        stock_volume))\n",
    "                        adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                        stock_quantity = int(units*row[\"stock_num_per_unit\"])\n",
    "                        temp_risk_lookback = min(risk_lookback, index)\n",
    "                        stock_temp = merged_df.loc[(index - temp_risk_lookback + 1):index].copy()\n",
    "                        stock_values = np.array((stock_temp[\"stock_open\"]/stock_temp[\"avg_ask_non_us_at\"])*stock_quantity) \n",
    "                        adr_values = np.array(merged_df.loc[(index - temp_risk_lookback):(index-1)][\"adr_close\"]*adr_quantity)\n",
    "                        sigma, var, max_drawdown_abs = get_risk_statistics(stock_values, adr_values, var_ci)\n",
    "                        if (var > portfolio_value_before_entering*var_limit or \n",
    "                            max_drawdown_abs > max_drawdown_limit*starting_cash or \n",
    "                            sigma > portfolio_value_before_entering*sigma_limit):\n",
    "                            frac = min((portfolio_value_before_entering*var_limit)/var, \n",
    "                                       (max_drawdown_limit*starting_cash)/max_drawdown_abs,\n",
    "                                      (portfolio_value_before_entering*sigma_limit)/sigma)\n",
    "                            units = int(frac*units)\n",
    "                            if units == 0:\n",
    "                                enter_cond2 = False\n",
    "                            adr_quantity = int(units*row[\"adr_num_per_unit\"])\n",
    "                            stock_quantity = int(units*row[\"stock_num_per_unit\"])  \n",
    "                        if units != 0:\n",
    "                            stock_pos += stock_quantity\n",
    "                            stock_px_fx = merged_df.loc[index+1,'stock_open']*long_multiplier\n",
    "                            stock_px = stock_px_fx/merged_df.loc[index+1,'avg_bid_non_us_at']\n",
    "                            cash -= stock_px*stock_quantity\n",
    "                            # We store the current cash/adr position, because the trade below will occur on the next day (EST)\n",
    "                            prev_cash, prev_adr_pos = cash, adr_pos\n",
    "\n",
    "                            adr_pos -= adr_quantity\n",
    "                            adr_px = merged_df.loc[index+1,'adr_open']*short_multiplier\n",
    "                            cash += adr_quantity*adr_px\n",
    "                            holding_period = 0\n",
    "                            trade_type = 2\n",
    "                            trade_records.append(\"Opening positions:\\n\")\n",
    "                            # Times in EST\n",
    "                            trade_records.append(f\"We bought {stock_quantity} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                            trade_records.append(f\"We sold {adr_quantity} shares of ADR at the price of {adr_px} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "\n",
    "                    elif exit_cond2:\n",
    "                        stock_px_fx = merged_df.loc[index+1,'stock_open']\n",
    "                        stock_px = stock_px_fx/merged_df.loc[index+1,'avg_ask_non_us_at']*short_multiplier\n",
    "                        cash += stock_pos*stock_px\n",
    "                        # We store the current cash/adr position, because the trade below will occur on the next day (EST)\n",
    "                        prev_cash, prev_adr_pos = cash, adr_pos\n",
    "                        \n",
    "                        adr_px = merged_df.loc[index+1,'adr_open']*long_multiplier\n",
    "                        cash -= abs(adr_pos)*adr_px\n",
    "                        trade_records.append(\"Closing positions:\\n\")\n",
    "                        # Times in EST\n",
    "                        trade_records.append(f\"We sold {stock_pos} shares of underlying stock at the price of {stock_px} USD ({stock_px_fx} foreign dollars) on {row['date']}\\n\")\n",
    "                        trade_records.append(f\"We bought {-adr_pos} shares of ADR at the price of {adr_px} on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                        stock_pos, adr_pos = 0, 0\n",
    "                        holding_period = None\n",
    "                        trade_type = None\n",
    "                        if cash > portfolio_value_before_entering:\n",
    "                            hits.append(1)\n",
    "                        else:\n",
    "                            hits.append(0)\n",
    "\n",
    "    ret = (portfolio_values[-1] - starting_cash)/starting_cash\n",
    "\n",
    "    return ret, trade_records, portfolio_values, hits, dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Hyperparameters:\n",
    "1. Lookback window\n",
    "2. Entry threshold\n",
    "3. Exit threshold\n",
    "4. Stop-loss threshold\n",
    "\n",
    "Steps:\n",
    "1. HP Tune each strategy for each of the pairs\n",
    "2. Store results for each pair in hp_log{version}.txt\n",
    "3. Store results for each strategy in results{version}.txt\n",
    "4. Store best strategy for each pair in results_all.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tune(pairs_trade_strategy, version, country, adr):\n",
    "    if version == '1' or version == '2':\n",
    "        hps = list(itertools.product(*[window_grid, entry_grid, exit_grid, stop_loss_grid]))\n",
    "    else:\n",
    "        hps = list(itertools.product(*[window_grid, entry_grid, entry_grid, exit_grid, exit_grid, stop_loss_grid, stop_loss_grid]))\n",
    "\n",
    "    merged_df = data_processing(country, adr, fx_dict)\n",
    "    hp_log = []\n",
    "    max_ret = -10000\n",
    "    max_ret_hps = (1,1,1,1)\n",
    "    max_ret_port = []\n",
    "    max_ret_hr = 0\n",
    "    max_ret_dd = 0\n",
    "    max_ret_dates = []\n",
    "    for hp in hps:\n",
    "        if version == '1' or version == '2':\n",
    "            ret, _, portfolio_values, hits, dates = pairs_trade_strategy(merged_df, \n",
    "                                                                         cash = 1000000,\n",
    "                                                                         lookback = hp[0], \n",
    "                                                                         entry = hp[1], \n",
    "                                                                         exit = hp[2], \n",
    "                                                                         stop_loss = hp[3])\n",
    "        else:\n",
    "            ret, _, portfolio_values, hits, dates = pairs_trade_strategy(merged_df, \n",
    "                                                                         cash = 1000000,\n",
    "                                                                         lookback = hp[0], \n",
    "                                                                         entry_cond1_val = hp[1], \n",
    "                                                                         entry_cond2_val = hp[2],\n",
    "                                                                         exit_cond1_val = hp[3],\n",
    "                                                                         exit_cond2_val = hp[4],\n",
    "                                                                         stop_loss_cond1 = hp[5],\n",
    "                                                                         stop_loss_cond2 = hp[6])\n",
    "        ret = np.round(ret*100, 2)\n",
    "        hit_ratio = 0\n",
    "        max_drawdown = 0\n",
    "        if hits:\n",
    "            hit_ratio = np.round(np.mean(hits)*100,2)\n",
    "            max_drawdown = np.round(calc_max_drawdown(portfolio_values)*100,2)\n",
    "        if ret > max_ret:\n",
    "            max_ret = ret\n",
    "            max_ret_hps = hp\n",
    "            max_ret_port = portfolio_values\n",
    "            max_ret_dates = dates\n",
    "            max_ret_hr = hit_ratio\n",
    "            max_ret_dd = max_drawdown\n",
    "        hp_log.append(f'{hp}: Return: {ret}%, Hit Ratio: {hit_ratio}%, Max Drawdown: {max_drawdown}%\\n')\n",
    "    if version == '1' or version == '2':\n",
    "        logs = [f'(Lookback, Entry, Exit, Stop-loss)\\n',\n",
    "                f'Best HPs: {max_ret_hps}, Return: {max_ret}%, Hit Ratio: {max_ret_hr}%, Max Drawdown: {max_ret_dd}%\\n']\n",
    "    else:\n",
    "        logs = [f'(Lookback, Entry1, Entry2, Exit1, Exit2, Stop-loss1, Stop-loss2)\\n',\n",
    "                f'Best HPs: {max_ret_hps}, Return: {max_ret}%, Hit Ratio: {max_ret_hr}%, Max Drawdown: {max_ret_dd}%\\n']\n",
    "    logs = logs + hp_log \n",
    "    fname = f'eric_jh_data/{country}/{adr}/hp_log{version}.txt' \n",
    "    f = open(fname, 'w')\n",
    "    f.writelines(logs)\n",
    "    f.close()\n",
    "    plot_returns(max_ret_dates, max_ret_port, country, adr, save = True)\n",
    "    best_hps = f'Country: {country}, ADR_Stock: {adr}, HPs: {max_ret_hps}, Return: {max_ret}%\\n'\n",
    "    fname = f'results{version}.txt'\n",
    "    f = open(fname, 'a')\n",
    "    f.writelines(best_hps)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "window_grid = [30, 60, 100]\n",
    "entry_grid = [1, 1.5, 2]\n",
    "exit_grid = [-0.5, 0, 0.5]\n",
    "stop_loss_grid = [2.5, 3, 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  28 | elapsed:  1.5min remaining: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  28 | elapsed:  2.2min remaining:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  28 | elapsed:  2.3min remaining:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  28 | elapsed:  2.4min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  28 | elapsed:  2.5min remaining:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  28 | elapsed:  3.5min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  28 | elapsed:  3.8min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  28 | elapsed:  3.9min remaining:   39.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "v1 = Parallel(n_jobs=-1, verbose = 10)(delayed(hp_tune)(pairs_trade_v1, '1', country, adr) for (country, adr) in list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  28 | elapsed:  1.5min remaining: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  28 | elapsed:  2.4min remaining:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  28 | elapsed:  2.5min remaining:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  28 | elapsed:  2.7min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  28 | elapsed:  2.8min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  28 | elapsed:  3.8min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  28 | elapsed:  4.1min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  28 | elapsed:  4.3min remaining:   43.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:  4.4min finished\n"
     ]
    }
   ],
   "source": [
    "v2 = Parallel(n_jobs=-1, verbose = 10)(delayed(hp_tune)(pairs_trade_v2, '2', country, adr) for (country, adr) in list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  28 | elapsed: 62.1min remaining: 517.5min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  28 | elapsed: 90.2min remaining: 330.7min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  28 | elapsed: 95.5min remaining: 201.5min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  28 | elapsed: 101.2min remaining: 134.9min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  28 | elapsed: 103.5min remaining: 89.7min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  28 | elapsed: 142.3min remaining: 79.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  28 | elapsed: 153.5min remaining: 51.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  28 | elapsed: 160.9min remaining: 26.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 43min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed: 163.7min finished\n"
     ]
    }
   ],
   "source": [
    "v3a = Parallel(n_jobs=-1, verbose = 10)(delayed(hp_tune)(pairs_trade_v3a, '3a', country, adr) for (country, adr) in list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  28 | elapsed: 62.7min remaining: 522.2min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  28 | elapsed: 96.5min remaining: 353.7min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  28 | elapsed: 104.7min remaining: 221.0min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  28 | elapsed: 107.8min remaining: 143.7min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  28 | elapsed: 112.5min remaining: 97.5min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  28 | elapsed: 154.2min remaining: 85.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  28 | elapsed: 167.2min remaining: 55.7min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  28 | elapsed: 179.3min remaining: 29.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed: 181.0min finished\n"
     ]
    }
   ],
   "source": [
    "v3b = Parallel(n_jobs=-1, verbose = 10)(delayed(hp_tune)(pairs_trade_v3b, '3b', country, adr) for (country, adr) in list_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate Results for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "variants = ['1', '2', '3a', '3b']\n",
    "for v in variants:\n",
    "    fname = f'results{v}.txt'\n",
    "    with open(fname) as f:\n",
    "        results.append(f.read())\n",
    "\n",
    "summ = []        \n",
    "for (country, adr) in list_pairs:\n",
    "    summ.append(f'Country: {country}, ADR_Stock: {adr}\\n')\n",
    "    for v in range(4):\n",
    "        ind = results[v].find(f'Country: {country}, ADR_Stock: {adr}')\n",
    "        end = results[v][ind:].find('\\n')\n",
    "        res = results[v][ind + len(f'Country: {country}, ADR_Stock: {adr}, '):ind + end]\n",
    "        summ.append(f'Variant {variants[v]}: ' + res + '\\n')\n",
    "        \n",
    "fname = 'results_all.txt'\n",
    "f = open(fname, 'w')\n",
    "f.writelines(summ)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort results for each pair based on return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sort_res(string):\n",
    "    ind = string.find('Return: ')\n",
    "    end = string[ind:].find('%')\n",
    "    return float(string[ind + 8:ind + end])\n",
    "\n",
    "for (country, adr) in list_pairs:\n",
    "    for v in variants:\n",
    "        fname = f'eric_jh_data/{country}/{adr}/hp_log{v}.txt' \n",
    "        f = open(fname, 'r')\n",
    "        res = f.readlines()\n",
    "        f.close()\n",
    "        sorted_res = sorted(res[2:], key = sort_res, reverse = True)\n",
    "        res = res[:2] + sorted_res\n",
    "        f = open(fname, 'w')\n",
    "        f.writelines(res)\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
